{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI_Project3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOUpSXdtJU4GPw08W98liQ8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"147a8c002bca4953bad3e947a632462e":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_983d86e56c7f486c96b8ef17991892b7","IPY_MODEL_7b73f4d736574c948df9dec3f923de41"],"layout":"IPY_MODEL_8dba8f8287a64cc0b15d0f06777a9ccf"}},"983d86e56c7f486c96b8ef17991892b7":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d37a302350c9418cbbfee074ccdbb9bf","placeholder":"​","style":"IPY_MODEL_c94bfaf2448c4b39af3146ca37e640ca","value":"0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\r"}},"7b73f4d736574c948df9dec3f923de41":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_83edeff79c03452c8144e95a352112cf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f2a0f42432942a6bee2be9f0fc82c53","value":1}},"8dba8f8287a64cc0b15d0f06777a9ccf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d37a302350c9418cbbfee074ccdbb9bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c94bfaf2448c4b39af3146ca37e640ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83edeff79c03452c8144e95a352112cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f2a0f42432942a6bee2be9f0fc82c53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"j-gilyQlVH5n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660683973430,"user_tz":-180,"elapsed":158154,"user":{"displayName":"יעל שוורץ","userId":"17640026806674125028"}},"outputId":"2770c5c3-fc67-46d0-bebe-34c7e0c6e292"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.ngc.nvidia.com, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nvidia-tensorrt\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-tensorrt/nvidia_tensorrt-8.4.1.5-cp37-none-linux_x86_64.whl (774.4 MB)\n","\u001b[K     |████████████████████████████████| 774.4 MB 16 kB/s \n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cuda-runtime-cu11/nvidia-cuda-runtime-cu11-2022.4.25.tar.gz (16 kB)\n","Collecting nvidia-cudnn-cu11\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cudnn-cu11/nvidia-cudnn-cu11-2022.5.19.tar.gz (16 kB)\n","Collecting nvidia-cublas-cu11\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cublas-cu11/nvidia-cublas-cu11-2022.4.8.tar.gz (16 kB)\n","Collecting nvidia-cublas-cu117\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cublas-cu117/nvidia_cublas_cu117-11.10.1.25-py3-none-manylinux1_x86_64.whl (333.1 MB)\n","\u001b[K     |████████████████████████████████| 333.1 MB 33 kB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (57.4.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (0.37.1)\n","Collecting nvidia-cuda-runtime-cu117\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cuda-runtime-cu117/nvidia_cuda_runtime_cu117-11.7.60-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[K     |████████████████████████████████| 849 kB 58.0 MB/s \n","\u001b[?25hCollecting nvidia-cudnn-cu116\n","  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cudnn-cu116/nvidia_cudnn_cu116-8.4.0.27-py3-none-manylinux1_x86_64.whl (719.3 MB)\n","\u001b[K     |████████████████████████████████| 719.3 MB 18 kB/s \n","\u001b[?25hBuilding wheels for collected packages: nvidia-cublas-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11\n","  Building wheel for nvidia-cublas-cu11 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvidia-cublas-cu11: filename=nvidia_cublas_cu11-2022.4.8-py3-none-any.whl size=15624 sha256=210455c5108b21d375c4830b31e15d5cf26a31859ead25e0f867d3df52ce3eb4\n","  Stored in directory: /root/.cache/pip/wheels/e2/c3/94/1ffd5bac267cfdc2b222a4ec6915278ef18a028a916b9a5ac3\n","  Building wheel for nvidia-cuda-runtime-cu11 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvidia-cuda-runtime-cu11: filename=nvidia_cuda_runtime_cu11-2022.4.25-py3-none-any.whl size=15696 sha256=ed64e224981d08d0baf9e91b41bb76ea0595af79685eb70c01464af723971dd8\n","  Stored in directory: /root/.cache/pip/wheels/df/fe/2b/e553db7867508b2268b14ac194e9ac5b3f51f21316c282c96c\n","  Building wheel for nvidia-cudnn-cu11 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvidia-cudnn-cu11: filename=nvidia_cudnn_cu11-2022.5.19-py3-none-any.whl size=15617 sha256=cc8186a153771c67520c3ed5c68875c4429ff7f2b34b4a9501d1f8add7640396\n","  Stored in directory: /root/.cache/pip/wheels/7c/32/69/9787704b5f889217708864db5e00812c8c1c349ef89084c59c\n","Successfully built nvidia-cublas-cu11 nvidia-cuda-runtime-cu11 nvidia-cudnn-cu11\n","Installing collected packages: nvidia-cudnn-cu116, nvidia-cuda-runtime-cu117, nvidia-cublas-cu117, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-tensorrt\n","Successfully installed nvidia-cublas-cu11-2022.4.8 nvidia-cublas-cu117-11.10.1.25 nvidia-cuda-runtime-cu11-2022.4.25 nvidia-cuda-runtime-cu117-11.7.60 nvidia-cudnn-cu11-2022.5.19 nvidia-cudnn-cu116-8.4.0.27 nvidia-tensorrt-8.4.1.5\n"]}],"source":["!pip install --upgrade --index-url https://pypi.ngc.nvidia.com nvidia-tensorrt"]},{"cell_type":"code","source":["# TensorRTUtils\n","!pip install pycuda \n","!pip install tensorrt\n","import tensorrt as trt\n","import pycuda.autoinit\n","import pycuda.driver as cuda\n","import numpy as np\n","import os\n","\n","class HostDeviceMem(object):\n","    def __init__(self, host_mem, device_mem):\n","        self.host = host_mem\n","        self.device = device_mem\n","\n","    def __str__(self):\n","        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n","\n","    def __repr__(self):\n","        return self.__str__()\n","\n","class ErrorRecorder(trt.IErrorRecorder):\n","    def __init__(self):\n","        trt.IErrorRecorder.__init__(self)\n","        self.errorsStack = []\n","\n","    def clear(self):\n","        self.errorsStack.clear()\n","    def get_error_code(self, arg0):\n","        #Error code saved in the error tuple first position\n","        return self.errorsStack[arg0][0]\n","    def get_error_desc(self, arg0):\n","        # Error code saved in the error tuple second position\n","        return self.errorsStack[arg0][1]\n","    def has_overflowed(self):\n","        return False\n","    def num_errors(self):\n","        return len(self.errorsStack)\n","    def report_error(self, arg0, arg1):\n","        error = (arg0, arg1)\n","        #Errors will be saved as a list of tuples, each tuple will be a pair of error code and error description\n","        self.errorsStack.append(error)\n","\n","class Logger(trt.ILogger):\n","    def __init__(self):\n","        trt.ILogger.__init__(self)\n","\n","    def log(self, severity, msg):\n","        if severity == trt.ILogger.INTERNAL_ERROR:\n","            print('INTERNAL_ERROR')\n","        elif severity == trt.ILogger.ERROR:\n","            print('TRT - ERROR')\n","        elif severity == trt.ILogger.WARNING:\n","            print('TRT - WARNING')\n","        elif severity == trt.ILogger.INFO:\n","            print('TRT - INFO')\n","        elif severity == trt.ILogger.VERBOSE:\n","            print('TRT - VERBOSE')\n","        else:\n","            print('TRT - Wrong severity')\n","\n","        print(msg)\n","\n","class Int8EntropyCalibrator(trt.IInt8EntropyCalibrator2):\n","    def __init__(self, calibrationSetPath = None, calibSet = None):\n","        # Whenever you specify a custom constructor for a TensorRT class,\n","        # you MUST call the constructor of the parent explicitly.\n","        trt.IInt8EntropyCalibrator2.__init__(self)\n","\n","        self.cacheFile = calibrationSetPath + '/CacheFile.bin'\n","        self.batchSize = 1\n","        self.currentIndex = 0\n","        self.deviceInput = None\n","        self.currentIndex = 0\n","        self.PreProcessedSetPath = calibrationSetPath + '/PreProcessedSet'\n","        self.PreProcessedSetCount = calibSet.n\n","        self.PreProcessedSize = calibSet[0][0].size * 4 #float\n","        self.currentIndex = 0\n","\n","        # Allocate enough memory for a whole batch.\n","        self.deviceInput = cuda.mem_alloc(self.PreProcessedSize)\n","\n","        if os.path.exists(self.cacheFile):\n","            print('Calibration cache file is already exist - ', self.cacheFile)\n","            return\n","\n","        filesCnt = os.listdir(self.PreProcessedSetPath)\n","\n","        if len(filesCnt) == self.PreProcessedSetCount:\n","            print('ERROR - Pre processed file set is exist!!!')\n","            return\n","\n","        if self.PreProcessedSetCount == 0:\n","            print('ERROR - Calibration set is empty!!!')\n","\n","        print('Start calibration batches build')\n","\n","        for idx in range(self.PreProcessedSetCount):\n","            preProcImg, label = calibSet.next()\n","            preProcessedFile = open(self.PreProcessedSetPath + '/' + str(idx) + '.bin', mode='wb')\n","            preProcImg.tofile(preProcessedFile)\n","            preProcessedFile.close()\n","\n","        print('End calibration batches build')\n","\n","    def get_algorithm(self):\n","        return trt.CalibrationAlgoType.ENTROPY_CALIBRATION_2\n","\n","    def get_batch_size(self):\n","        return self.batchSize\n","\n","    # TensorRT passes along the names of the engine bindings to the get_batch function.\n","    # You don't necessarily have to use them, but they can be useful to understand the order of\n","    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n","    def get_batch(self, names):\n","        if not self.currentIndex < self.PreProcessedSetCount:\n","            return None\n","\n","        print('Get pre processed file index - ', not self.currentIndex)\n","\n","        batchData = np.fromfile(self.PreProcessedSetPath + '/' + str(self.currentIndex) + '.bin', dtype=np.single)\n","        cuda.memcpy_htod(self.deviceInput, batchData)\n","        self.currentIndex += 1\n","\n","        return [self.deviceInput]\n","\n","    def read_calibration_cache(self):\n","        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n","        if os.path.exists(self.cacheFile):\n","            with open(self.cacheFile, \"rb\") as f:\n","                return f.read()\n","\n","    def write_calibration_cache(self, cache):\n","        with open(self.cacheFile, \"wb\") as f:\n","            f.write(cache)\n","\n","logger = Logger()\n","errorRecorder = ErrorRecorder()\n","\n","builder = trt.Builder(logger)\n","builder.max_batch_size = 1\n","\n","calib = None\n","config = builder.create_builder_config()\n","config.max_workspace_size = 1073741824\n","\n","optimizationProfiler = builder.create_optimization_profile()\n","\n","networkFlags = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n","network = builder.create_network(networkFlags)\n","parser = trt.OnnxParser(network, logger)\n","runtime = trt.Runtime(logger)\n","\n","engine = None\n","context = None\n","\n","modelName = None\n","\n","inputs = []\n","outputs = []\n","bindings = []\n","stream = None\n","\n","def TrtModelParse(modelPath):\n","    global modelName\n","    global parser\n","    global network\n","\n","    modelName = modelPath.split('.')[0]\n","    parseResult = parser.parse_from_file(modelPath)\n","\n","    if (not parseResult):\n","        for error in range(parser.num_errors):\n","            print(str(parser.get_error(error)))\n","    else:\n","        print(\"Model parsing OK!\")\n","\n","        print(\"Network Description\")\n","\n","        inputs = [network.get_input(i) for i in range(network.num_inputs)]\n","        outputs = [network.get_output(i) for i in range(network.num_outputs)]\n","\n","        for input in inputs:\n","            print(\"Input '{}' with shape {} and dtype {}\".format(input.name, input.shape, input.dtype))\n","        for output in outputs:\n","            print(\"Output '{}' with shape {} and dtype {}\".format(output.name, output.shape, output.dtype))\n","\n","def TrtModelOptimizeAndSerialize(precision = 'fp32',calibPath=\"\", calibSet=None):\n","    global modelName\n","    global builder\n","    global optimizationProfiler\n","    global calib\n","    global config\n","    global network\n","    global engine\n","    global runtime\n","\n","    modelOptName = modelName + precision + '.trt.engine'\n","\n","    if os.path.exists(modelOptName):\n","        with open(modelOptName, 'rb') as f:\n","            engine = runtime.deserialize_cuda_engine(f.read())\n","    else:\n","        inputs = [network.get_input(i) for i in range(network.num_inputs)]\n","        input = network.get_input(0)\n","\n","        inputShape = [1, input.shape[1], input.shape[2], input.shape[3]]\n","\n","        optimizationProfiler.set_shape(input.name, inputShape, inputShape, inputShape)\n","\n","        config.add_optimization_profile(optimizationProfiler)\n","\n","        if precision == 'fp16':\n","            if builder.platform_has_fast_fp16:\n","                config.set_flag(trt.BuilderFlag.FP16)\n","        elif precision == 'int8':\n","            if builder.platform_has_fast_int8:\n","                if builder.platform_has_fast_fp16:\n","                    # Also enable fp16, as some layers may be even more efficient in fp16 than int8\n","                    config.set_flag(trt.BuilderFlag.FP16)\n","\n","                config.set_flag(trt.BuilderFlag.INT8)\n","\n","                calib = Int8EntropyCalibrator(calibPath, calibSet)\n","                config.int8_calibrator = calib\n","\n","        engine = builder.build_engine(network, config)\n","\n","        serializedEngine = engine.serialize()\n","\n","        engineFD = open(modelOptName, 'wb')\n","        engineFD.write(serializedEngine)\n","        engineFD.close()\n","\n","    print('TRT engine - ', engine.device_memory_size, ' Bytes')\n","    engineDeviceMemory = 0\n","    engineDeviceMemory += engine.device_memory_size\n","    print('TRT engine number of layers - ', engine.num_layers)\n","    print('TRT engine number of bindings - ', engine.num_bindings)\n","    print('TRT engine number of profils - ', engine.num_optimization_profiles)\n","\n","    print('Completion optimized model')\n","\n","def ModelInferSetup():\n","    global context\n","    global engine\n","    global inputs\n","    global outputs\n","    global bindings\n","    global stream\n","\n","    stream = cuda.Stream()\n","\n","    #Over all Tensors inputs & outputs of the TRT engine\n","    #TRT hold first all Tensors inputs and after the Tensor outptus\n","    for binding in engine:\n","        #Get current binded Tensor volume size in elemente units\n","        size = trt.volume(engine.get_binding_shape(binding))\n","        #Get current binded Tensor element type\n","        dtype = trt.nptype(engine.get_binding_dtype(binding))\n","        # Allocate host page locked bbuffer\n","        host_mem = cuda.pagelocked_empty(size, dtype)\n","        # Allocate device bbuffer\n","        device_mem = cuda.mem_alloc(host_mem.nbytes)\n","        # Append the device buffer to device bindings.\n","        bindings.append(int(device_mem))\n","        # Append to the appropriate list.\n","        if engine.binding_is_input(binding):\n","            inputs.append(HostDeviceMem(host_mem, device_mem))\n","        else:\n","            outputs.append(HostDeviceMem(host_mem, device_mem))\n","\n","    # Contexts are used to perform inference.\n","    context = engine.create_execution_context()\n","    context.error_recorder = errorRecorder\n","\n","def Inference(externalnputs = None):\n","\n","    global context\n","    global stream\n","    global inputs\n","    global outputs\n","    global bindings\n","\n","    try:\n","        #verify that TRT context generated successfully\n","        if context is not None:\n","            #Verify that inputs to inference are exist\n","            if externalnputs is not None:\n","                #Copy all Tensors inputs data from user memory to TRT host page locked memory before loading it to the device\n","                if len(externalnputs) == len(inputs):\n","                    for index in range(len(externalnputs)):\n","                        if len(inputs[index].host) == externalnputs[index].size:\n","                            np.copyto(inputs[index].host, externalnputs[index].ravel())\n","                        else:\n","                            print('TRT external input size - ', externalnputs[index].size,\n","                                  ' is not equal to model inputs size - ', len(inputs[index].host))\n","                            return None\n","\n","                    # Transfer input data to the GPU from the host page locked memory.\n","                    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n","                    # Run asynchronously inference using the user\\internal stream.\n","                    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n","                    # Transfer predictions back from the GPU.\n","                    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n","\n","                    stream.synchronize()\n","                    # Build a list of Tensors outputs and return only the host outputs.\n","                    return [out.host for out in outputs]\n","                else:\n","                    print('External inputs list size - ', len(externalnputs), ' is not equal to model inputs list size - ', len(inputs))\n","                    return None\n","            else:\n","                print('External inputs list is None ERROR')\n","                return None\n","    except BaseException as e:\n","        msg = e\n","        print('TRT inference exception ERROR - ', msg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzctBFwmVnAo","executionInfo":{"status":"ok","timestamp":1660683987158,"user_tz":-180,"elapsed":9835,"user":{"displayName":"יעל שוורץ","userId":"17640026806674125028"}},"outputId":"041ff215-58b0-4e87-db6d-35e586bf489f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2022.1)\n","Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n","Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2022.1.12)\n","Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.2.1)\n","Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (2.5.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.12.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.8.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorrt in /usr/local/lib/python3.7/dist-packages (0.0.1)\n","TRT - INFO\n","[MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 0, GPU 244 (MiB)\n","TRT - INFO\n","[MemUsageChange] Init builder kernel library: CPU +0, GPU +68, now: CPU 0, GPU 312 (MiB)\n","TRT - INFO\n","[MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 0, GPU 312 (MiB)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:144: DeprecationWarning: Use set_memory_pool_limit instead.\n"]}]},{"cell_type":"code","source":["# onnxUtils\n","!pip install tf2onnx onnx onnxsim\n","import json\n","import time\n","import tf2onnx\n","import onnx\n","#import onnxsim\n","import os.path\n","\n","\n","# Save model into h5 and ONNX formats\n","def convertKerasToONNX(name, model, overwrite_existing = False):\n","    modelFile = name + '.onnx'\n","    if not os.path.isfile(modelFile) or overwrite_existing:\n","        # Save model with ONNX format\n","        (onnx_model_proto, storage) = tf2onnx.convert.from_keras(model)\n","        with open(os.path.join(modelFile), \"wb\") as f:\n","            f.write(onnx_model_proto.SerializeToString())\n","            f.close()\n","    \n","    return modelFile, onnx_model_proto, storage\n","\n","def ModelOnnxCheck(name):\n","\n","    msg = 'OK'\n","    isCheckOk = True\n","\n","    print(\"===============================================================\")\n","    print(\"Onnx model check report:\")\n","\n","    try:\n","        # Perform basic check on the model input\n","        onnx.checker.check_model(name + '.onnx')\n","        isCheckOk = True\n","    except onnx.checker.ValidationError as e:\n","        msg = e\n","        isCheckOk=False\n","    except BaseException as e:\n","        msg = e\n","        isCheckOk=False\n","\n","    if isCheckOk:\n","        print('Model check completed Successfully')\n","    else:\n","        print('ERROR - Model check failure')\n","\n","    print('Model onnx checker, check model - ', msg)\n","\n","    return isCheckOk\n","\n","def RemoveInitializerFromInput(model, modelPath):\n","    modelGraphInputs = model.graph.input\n","    startInputsCount = len(modelGraphInputs)\n","\n","    nameToInput = {}\n","    for input in modelGraphInputs:\n","        nameToInput[input.name] = input\n","\n","    for initializer in model.graph.initializer:\n","        if initializer.name in nameToInput:\n","            modelGraphInputs.remove(nameToInput[initializer.name])\n","\n","    endInputsCount = len(modelGraphInputs)\n","\n","    if startInputsCount != endInputsCount:\n","        print('Model includes several Initializers which considered as inputs to the graph - ', startInputsCount - endInputsCount)\n","        print('All Initializers were removed from graph inputs')\n","        print('Replace the model *.onx file with the updated one')\n","        onnx.save(model, modelPath)\n","\n","def ProcessModelInputs(model, modelPath):\n","    RemoveInitializerFromInput(model, modelPath)\n","    modelGraphInputs = model.graph.input\n","\n","    modelInputsDims = {}\n","    modelDynamicInputsDict = {}\n","    modelInputs = modelGraphInputs\n","    modelInputsNames = []\n","    print(str(modelInputs))\n","\n","    for tensorInput in modelInputs:\n","        isInputDynamic = False\n","        modelDynamicInputShape = []\n","        for dim in tensorInput.type.tensor_type.shape.dim:\n","            if dim.dim_value == 0:\n","                isInputDynamic = True\n","                print('CAUTION!!! - Tensor input name' + ' - ', tensorInput.name, ', dimension - ' , dim.dim_param, ', set its value to 1 for Onnx simplify operation')\n","                modelDynamicInputShape.append(1)\n","            else:\n","                modelDynamicInputShape.append(dim.dim_value)\n","\n","        modelInputsNames.append(tensorInput.name)\n","\n","        if isInputDynamic is True:\n","            modelDynamicInputsDict[tensorInput.name] = modelDynamicInputShape\n","\n","    return modelDynamicInputsDict\n","\n","def ModelSimplify(name):\n","\n","    msg = 'OK'\n","    nameSimp = name + 'Simp'\n","    model = None\n","    isSimplifiedOK = True\n","\n","    if os.path.exists(nameSimp + '.onnx'):\n","        print('Model Onnx simplify is already exist, No model check and\\or simplify operations is required')\n","        model = onnx.load(nameSimp + '.onnx')\n","        isSimplifiedOK = True\n","    else:\n","        print(\"===============================================================\")\n","        print(\"Onnx model simplifier report:\")\n","        model = onnx.load(name + '.onnx')\n","\n","        modelDynamicInputsDict = ProcessModelInputs(model, name + '.onnx')\n","\n","        try:\n","            print('Start model onnx simplify...')\n","            # Perform simplification on the model input\n","            model, check = onnxsim.simplify(model,input_shapes=modelDynamicInputsDict,\n","                                                  dynamic_input_shape=(len(modelDynamicInputsDict) > 0))\n","            print('Completion model onnx simplify')\n","            if (check):\n","                isSimplifiedOK = True\n","                print('Onnx simplification success!')\n","                print('Save Onnx simplified model to - ', nameSimp + '.onnx')\n","                onnx.save(model, nameSimp + '.onnx')\n","            else:\n","                isSimplifiedOK = False\n","                print('Onnx simplification failure!')\n","                print('Simplified Onnx model could not be generated and validated')\n","        except BaseException as e:\n","            print('Onnx simplification exception - ', e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yU_AzfphVoRZ","executionInfo":{"status":"ok","timestamp":1660684040601,"user_tz":-180,"elapsed":8126,"user":{"displayName":"יעל שוורץ","userId":"17640026806674125028"}},"outputId":"5acc4916-3d8c-4d36-b58e-08fa9c815f80"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tf2onnx in /usr/local/lib/python3.7/dist-packages (1.12.0)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.12.0)\n","Requirement already satisfied: onnxsim in /usr/local/lib/python3.7/dist-packages (0.4.7)\n","Requirement already satisfied: flatbuffers~=1.12 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.12)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.7/dist-packages (from onnxsim) (12.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (1.24.3)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->onnxsim) (2.6.1)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich->onnxsim) (0.9.1)\n"]}]},{"cell_type":"code","source":["# wandb_helpers\n","!pip install wandb\n","from datetime import datetime\n","import wandb\n","from collections import namedtuple\n","import numpy as np\n","import os\n","import tensorflow as tf\n","\n","Dataset = namedtuple(\"Dataset\", [\"images\", \"labels\"])\n","dataset_names = [\"training\", \"validation\", \"test\"]\n","\n","def start_wandb_run(model_name, config):\n","    timestamp = datetime.now().strftime(\"%H%M%S\")\n","    return wandb.init(project=f\"ml-p2\", entity=\"ml-p2\", name=f\"{model_name}-{timestamp}\" , \n","        notes = f\"Training FCNN model @{timestamp}\", config = config)\n","\n","def read_datasets(wandb_run, dataset_tag = \"latest\"):\n","    '''\n","    Read all datasets from W&B.\n","    Usage example: train_set, validation_set, test_set = wbh.read_datasets(run)\n","    '''\n","    artifact = wandb_run.use_artifact(f'ml-p2/ml-p2/fashion-mnist:{dataset_tag}', type='dataset')\n","    data_dir = artifact.download()\n","    return [ read_dataset(data_dir, ds_name) for ds_name in dataset_names ]\n","\n","def read_dataset(data_dir, ds_name):\n","    filename = ds_name + \".npz\"\n","    data = np.load(os.path.join(data_dir, filename))\n","    return Dataset(images = data[\"x\"], labels = data[\"y\"])\n","\n","def read_model(wandb_run, model_name, model_tag = \"latest\") -> tf.keras.models.Model:\n","    artifact = wandb_run.use_artifact(f'ml-p2/ml-p2/{model_name}:{model_tag}', type='model')\n","    artifact_dir = artifact.download()\n","    return tf.keras.models.load_model(artifact_dir)\n","\n","def save_model(wandb_run, model, config, model_name, model_description):\n","    model_file = f'./saved-models/{model_name}.tf'\n","    tf.keras.models.save_model(model, model_file)\n","    model_artifact = wandb.Artifact(model_name, type = \"model\", description=model_description, metadata= dict(config))\n","    model_artifact.add_dir(model_file)\n","    wandb_run.log_artifact(model_artifact)\n","\n","def load_best_model(sweep_id):\n","    api = wandb.Api()\n","    sweep = api.sweep(f\"ml-p2/ml-p2/{sweep_id}\")\n","    runs = sorted(sweep.runs,\n","        key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)\n","    val_acc = runs[0].summary.get(\"val_accuracy\", 0)\n","    print(f\"Best run {runs[0].name} with {val_acc} validation accuracy\")\n","\n","    model_file = runs[0].file(\"model-best.h5\").download(replace=True)\n","    model_file.close()\n","\n","if (__name__ == \"__main__\"):\n","    load_best_model(\"6zmewzd0\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_iT8JNVVobY","executionInfo":{"status":"ok","timestamp":1660684472171,"user_tz":-180,"elapsed":8767,"user":{"displayName":"יעל שוורץ","userId":"17640026806674125028"}},"outputId":"bfd8d1e2-d9e5-4f40-c5ab-6b503aa42e39"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Best run Conv-142858 with 0.9169999957084656 validation accuracy\n"]}]},{"cell_type":"code","source":["# trt-inference\n","#!pip install sklearn -qqq\n","\n","#!pip install TensorRTUtils onnxUtils wandb_helpers\n","import time\n","from sklearn.metrics import classification_report, confusion_matrix\n","import tensorflow as tf\n","import tensorrt as trt\n","#from TensorRTUtils import *\n","import onnx\n","import tf2onnx\n","import numpy as np\n","from PIL import Image as im\n","import os\n","#from onnxUtils import convertKerasToONNX\n","#import wandb_helpers as wbh\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt     \n","\n","modelName = \"FCNN\"\n","\n","'''\n","Stage 1: Load an existing model\n","===============================\n","In this part we load the model we created in the previous project\n","which is built to infer from FASHION-MNIST images.\n","It is not a sofisticated model, but the idea to use something we\n","know.\n","'''\n","dataset_path = '.\\\\artifacts\\\\fashion-mnist-v2'\n","\n","if not os.path.exists(dataset_path):\n","    with start_wandb_run(\"FCNN-metrics\", None) as run:\n","        train_set, validation_set, test_set = read_datasets(run)\n","        model = read_model(run, \"FCNN\", \"latest\")\n","else:\n","    test_set = read_dataset('.\\\\artifacts\\\\fashion-mnist-v2', 'test')\n","    model = tf.keras.models.load_model('.\\\\artifacts\\\\FCNN-v3')\n","\n","'''\n","Stage 2: Convert to ONNX\n","========================\n","Convert the model to ONNX and save it to a file. This will allow\n","us to load the model into a tensor-rt engine.\n","'''\n","modelFile, _, _ = convertKerasToONNX(modelName, model, True)\n","\n","'''\n","Stage 3: Create the tensor-rt engine\n","====================================\n","Now that we a model file, we can load it into a \n","tensor rt engine.\n","We use FP 32 precision.\n","'''\n","TrtModelParse(modelFile)\n","TrtModelOptimizeAndSerialize(precision='fp32')\n","ModelInferSetup()\n","\n","'''\n","Stage 4: Inference\n","==================\n","Now the model is ready for inference. The model is executed several\n","times on different images from the test set we've loaded on Stage 1\n","'''\n","inputs = []\n","\n","startTimeCpu = time.time()\n","for i in range(len(test_set)):\n","    img = test_set.images[i]\n","    lbl = test_set.labels[i]\n","    inputs.append(img)\n","    outputsTrt = Inference(externalnputs=inputs)\n","    #print(' topClassIdx - ', np.argmax(outputsTrt[0]))\n","    inputs.clear()\n","    \n","    \n","endTimeCpu = time.time()\n","\n","# total time taken\n","averageTime = (endTimeCpu - startTimeCpu) / 1e-3 / len(test_set)\n","print(f\"TRT Keras inference average time is: {averageTime} milliseconds\")\n","print(f\"TRT Keras inference average FPS is: {1000 / averageTime}\")\n","\n","# Perform the DlewareAnalyzer inference with TRT & ORT\n","\n","#np.testing.assert_allclose(kerasPredictions, onnxPredictions[0], rtol=0, atol=1e-05, err_msg='Keras Vs. Onnx Failure!!!')\n","\n","\n","#y_test = np.argmax(test_set.labels)\n","# predictions = model.predict(test_set.images)\n","# y_test = np.argmax(predictions, axis = 1)\n","# print (classification_report(test_set.labels, y_test))\n","# cm = confusion_matrix(test_set.labels, y_test)\n","\n","# class_names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n","\n","# ax = plt.subplot()\n","# h = sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# # labels, title and ticks\n","# ax.set_xlabel('Predicted labels')\n","# ax.set_ylabel('True labels')\n","# ax.set_title('Confusion Matrix')\n","# ax.xaxis.set_ticklabels(class_names)\n","# ax.yaxis.set_ticklabels(class_names)\n","\n","# plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["147a8c002bca4953bad3e947a632462e","983d86e56c7f486c96b8ef17991892b7","7b73f4d736574c948df9dec3f923de41","8dba8f8287a64cc0b15d0f06777a9ccf","d37a302350c9418cbbfee074ccdbb9bf","c94bfaf2448c4b39af3146ca37e640ca","83edeff79c03452c8144e95a352112cf","4f2a0f42432942a6bee2be9f0fc82c53"]},"id":"EEa4aCwOWALB","executionInfo":{"status":"error","timestamp":1660684829427,"user_tz":-180,"elapsed":35181,"user":{"displayName":"יעל שוורץ","userId":"17640026806674125028"}},"outputId":"d51f3d78-f9ad-4a40-bbb6-b0c00b52edd2"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnirsch\u001b[0m (\u001b[33mml-p2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220816_211952-1dbysuem</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/ml-p2/ml-p2/runs/1dbysuem\" target=\"_blank\">FCNN-metrics-211952</a></strong> to <a href=\"https://wandb.ai/ml-p2/ml-p2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact fashion-mnist:latest, 418.77MB. 3 files... Done. 0:0:7.0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147a8c002bca4953bad3e947a632462e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">FCNN-metrics-211952</strong>: <a href=\"https://wandb.ai/ml-p2/ml-p2/runs/1dbysuem\" target=\"_blank\">https://wandb.ai/ml-p2/ml-p2/runs/1dbysuem</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220816_211952-1dbysuem/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n"]},{"output_type":"stream","name":"stdout","text":["TRT - INFO\n","----------------------------------------------------------------\n","TRT - INFO\n","Input filename:   FCNN.onnx\n","TRT - INFO\n","ONNX IR version:  0.0.7\n","TRT - INFO\n","Opset version:    13\n","TRT - INFO\n","Producer name:    tf2onnx\n","TRT - INFO\n","Producer version: 1.12.0 a58786\n","TRT - INFO\n","Domain:           \n","TRT - INFO\n","Model version:    0\n","TRT - INFO\n","Doc string:       \n","TRT - INFO\n","----------------------------------------------------------------\n","TRT - VERBOSE\n","Registered plugin creator - ::GridAnchor_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::GridAnchorRect_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::NMS_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::Reorg_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::Region_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::Clip_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::LReLU_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::PriorBox_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::Normalize_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::ScatterND version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::RPROI_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::BatchedNMS_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::BatchTilePlugin_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::FlattenConcat_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::CropAndResize version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::CropAndResizeDynamic version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::DetectionLayer_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::EfficientNMS_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::ProposalDynamic version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::Proposal version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::ProposalLayer_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::PyramidROIAlign_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::ResizeNearest_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::Split version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::SpecialSlice_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::InstanceNormalization_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::InstanceNormalization_TRT version 2\n","TRT - VERBOSE\n","Registered plugin creator - ::CoordConvAC version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::DecodeBbox3DPlugin version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::GenerateDetection_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::MultilevelCropAndResize_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::MultilevelProposeROI_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::NMSDynamic_TRT version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::PillarScatterPlugin version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::VoxelGeneratorPlugin version 1\n","TRT - VERBOSE\n","Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1\n","TRT - VERBOSE\n","Adding network input: input_1 with dtype: float32, dimensions: (-1, 28, 28, 1)\n","TRT - VERBOSE\n","Registering tensor: input_1 for ONNX tensor: input_1\n","TRT - VERBOSE\n","Importing initializer: sequential/dense_3/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: sequential/dense_3/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: sequential/dense_2/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: sequential/dense_2/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: sequential/dense_1/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: sequential/dense_1/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: sequential/dense/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: sequential/dense/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Importing initializer: const_fold_opt__7\n","TRT - WARNING\n","onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n","TRT - VERBOSE\n","Parsing node: sequential/flatten/Reshape [Reshape]\n","TRT - VERBOSE\n","Searching for input: input_1\n","TRT - VERBOSE\n","Searching for input: const_fold_opt__7\n","TRT - VERBOSE\n","sequential/flatten/Reshape [Reshape] inputs: [input_1 -> (-1, 28, 28, 1)[FLOAT]], [const_fold_opt__7 -> (2)[INT32]], \n","TRT - VERBOSE\n","Registering layer: sequential/flatten/Reshape for ONNX node: sequential/flatten/Reshape\n","TRT - VERBOSE\n","Registering tensor: sequential/flatten/Reshape:0 for ONNX tensor: sequential/flatten/Reshape:0\n","TRT - VERBOSE\n","sequential/flatten/Reshape [Reshape] outputs: [sequential/flatten/Reshape:0 -> (-1, 784)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense/MatMul [MatMul]\n","TRT - VERBOSE\n","Searching for input: sequential/flatten/Reshape:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense/MatMul [MatMul] inputs: [sequential/flatten/Reshape:0 -> (-1, 784)[FLOAT]], [sequential/dense/MatMul/ReadVariableOp:0 -> (784, 155)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense/MatMul for ONNX node: sequential/dense/MatMul\n","TRT - VERBOSE\n","Registering tensor: sequential/dense/MatMul:0 for ONNX tensor: sequential/dense/MatMul:0\n","TRT - VERBOSE\n","sequential/dense/MatMul [MatMul] outputs: [sequential/dense/MatMul:0 -> (-1, 155)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense/BiasAdd [Add]\n","TRT - VERBOSE\n","Searching for input: sequential/dense/MatMul:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense/BiasAdd [Add] inputs: [sequential/dense/MatMul:0 -> (-1, 155)[FLOAT]], [sequential/dense/BiasAdd/ReadVariableOp:0 -> (155)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense/BiasAdd for ONNX node: sequential/dense/BiasAdd\n","TRT - VERBOSE\n","Registering tensor: sequential/dense/BiasAdd:0 for ONNX tensor: sequential/dense/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense/BiasAdd [Add] outputs: [sequential/dense/BiasAdd:0 -> (-1, 155)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense/Relu [Relu]\n","TRT - VERBOSE\n","Searching for input: sequential/dense/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense/Relu [Relu] inputs: [sequential/dense/BiasAdd:0 -> (-1, 155)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense/Relu for ONNX node: sequential/dense/Relu\n","TRT - VERBOSE\n","Registering tensor: sequential/dense/Relu:0 for ONNX tensor: sequential/dense/Relu:0\n","TRT - VERBOSE\n","sequential/dense/Relu [Relu] outputs: [sequential/dense/Relu:0 -> (-1, 155)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_1/MatMul [MatMul]\n","TRT - VERBOSE\n","Searching for input: sequential/dense/Relu:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense_1/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense_1/MatMul [MatMul] inputs: [sequential/dense/Relu:0 -> (-1, 155)[FLOAT]], [sequential/dense_1/MatMul/ReadVariableOp:0 -> (155, 144)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_1/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense_1/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense_1/MatMul for ONNX node: sequential/dense_1/MatMul\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_1/MatMul:0 for ONNX tensor: sequential/dense_1/MatMul:0\n","TRT - VERBOSE\n","sequential/dense_1/MatMul [MatMul] outputs: [sequential/dense_1/MatMul:0 -> (-1, 144)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_1/BiasAdd [Add]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_1/MatMul:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense_1/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense_1/BiasAdd [Add] inputs: [sequential/dense_1/MatMul:0 -> (-1, 144)[FLOAT]], [sequential/dense_1/BiasAdd/ReadVariableOp:0 -> (144)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_1/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense_1/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense_1/BiasAdd for ONNX node: sequential/dense_1/BiasAdd\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_1/BiasAdd:0 for ONNX tensor: sequential/dense_1/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense_1/BiasAdd [Add] outputs: [sequential/dense_1/BiasAdd:0 -> (-1, 144)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_1/Relu [Relu]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_1/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense_1/Relu [Relu] inputs: [sequential/dense_1/BiasAdd:0 -> (-1, 144)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_1/Relu for ONNX node: sequential/dense_1/Relu\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_1/Relu:0 for ONNX tensor: sequential/dense_1/Relu:0\n","TRT - VERBOSE\n","sequential/dense_1/Relu [Relu] outputs: [sequential/dense_1/Relu:0 -> (-1, 144)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_2/MatMul [MatMul]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_1/Relu:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense_2/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense_2/MatMul [MatMul] inputs: [sequential/dense_1/Relu:0 -> (-1, 144)[FLOAT]], [sequential/dense_2/MatMul/ReadVariableOp:0 -> (144, 63)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_2/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense_2/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense_2/MatMul for ONNX node: sequential/dense_2/MatMul\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_2/MatMul:0 for ONNX tensor: sequential/dense_2/MatMul:0\n","TRT - VERBOSE\n","sequential/dense_2/MatMul [MatMul] outputs: [sequential/dense_2/MatMul:0 -> (-1, 63)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_2/BiasAdd [Add]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_2/MatMul:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense_2/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense_2/BiasAdd [Add] inputs: [sequential/dense_2/MatMul:0 -> (-1, 63)[FLOAT]], [sequential/dense_2/BiasAdd/ReadVariableOp:0 -> (63)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_2/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense_2/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense_2/BiasAdd for ONNX node: sequential/dense_2/BiasAdd\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_2/BiasAdd:0 for ONNX tensor: sequential/dense_2/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense_2/BiasAdd [Add] outputs: [sequential/dense_2/BiasAdd:0 -> (-1, 63)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_2/Relu [Relu]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_2/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense_2/Relu [Relu] inputs: [sequential/dense_2/BiasAdd:0 -> (-1, 63)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_2/Relu for ONNX node: sequential/dense_2/Relu\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_2/Relu:0 for ONNX tensor: sequential/dense_2/Relu:0\n","TRT - VERBOSE\n","sequential/dense_2/Relu [Relu] outputs: [sequential/dense_2/Relu:0 -> (-1, 63)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_3/MatMul [MatMul]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_2/Relu:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense_3/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense_3/MatMul [MatMul] inputs: [sequential/dense_2/Relu:0 -> (-1, 63)[FLOAT]], [sequential/dense_3/MatMul/ReadVariableOp:0 -> (63, 10)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_3/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense_3/MatMul/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense_3/MatMul for ONNX node: sequential/dense_3/MatMul\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_3/MatMul:0 for ONNX tensor: sequential/dense_3/MatMul:0\n","TRT - VERBOSE\n","sequential/dense_3/MatMul [MatMul] outputs: [sequential/dense_3/MatMul:0 -> (-1, 10)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_3/BiasAdd [Add]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_3/MatMul:0\n","TRT - VERBOSE\n","Searching for input: sequential/dense_3/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","sequential/dense_3/BiasAdd [Add] inputs: [sequential/dense_3/MatMul:0 -> (-1, 10)[FLOAT]], [sequential/dense_3/BiasAdd/ReadVariableOp:0 -> (10)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_3/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense_3/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","Registering layer: sequential/dense_3/BiasAdd for ONNX node: sequential/dense_3/BiasAdd\n","TRT - VERBOSE\n","Registering tensor: sequential/dense_3/BiasAdd:0 for ONNX tensor: sequential/dense_3/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense_3/BiasAdd [Add] outputs: [sequential/dense_3/BiasAdd:0 -> (-1, 10)[FLOAT]], \n","TRT - VERBOSE\n","Parsing node: sequential/dense_3/Softmax [Softmax]\n","TRT - VERBOSE\n","Searching for input: sequential/dense_3/BiasAdd:0\n","TRT - VERBOSE\n","sequential/dense_3/Softmax [Softmax] inputs: [sequential/dense_3/BiasAdd:0 -> (-1, 10)[FLOAT]], \n","TRT - VERBOSE\n","Registering layer: sequential/dense_3/Softmax for ONNX node: sequential/dense_3/Softmax\n","TRT - VERBOSE\n","Registering tensor: dense_3_0 for ONNX tensor: dense_3\n","TRT - VERBOSE\n","sequential/dense_3/Softmax [Softmax] outputs: [dense_3 -> (-1, 10)[FLOAT]], \n","TRT - VERBOSE\n","Marking dense_3_0 as output: dense_3\n","Model parsing OK!\n","Network Description\n","Input 'input_1' with shape (-1, 28, 28, 1) and dtype DataType.FLOAT\n","Output 'dense_3' with shape (-1, 10) and dtype DataType.FLOAT\n","TRT - VERBOSE\n","Applying generic optimizations to the graph for inference.\n","TRT - VERBOSE\n","Original: 26 layers\n","TRT - VERBOSE\n","After dead-layer removal: 26 layers\n","TRT - VERBOSE\n","Running: ConstShuffleFusion on sequential/dense/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","ConstShuffleFusion: Fusing sequential/dense/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 4) [Shuffle]\n","TRT - VERBOSE\n","Running: ConstShuffleFusion on sequential/dense_1/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","ConstShuffleFusion: Fusing sequential/dense_1/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 10) [Shuffle]\n","TRT - VERBOSE\n","Running: ConstShuffleFusion on sequential/dense_2/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","ConstShuffleFusion: Fusing sequential/dense_2/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 16) [Shuffle]\n","TRT - VERBOSE\n","Running: ConstShuffleFusion on sequential/dense_3/BiasAdd/ReadVariableOp:0\n","TRT - VERBOSE\n","ConstShuffleFusion: Fusing sequential/dense_3/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 22) [Shuffle]\n","TRT - VERBOSE\n","Running: ShuffleErasure on (Unnamed Layer* 25) [Shuffle]\n","TRT - VERBOSE\n","Removing (Unnamed Layer* 25) [Shuffle]\n","TRT - VERBOSE\n","After Myelin optimization: 21 layers\n","TRT - VERBOSE\n","Running: MatMulToConvTransform on sequential/dense/MatMul\n","TRT - VERBOSE\n","Convert layer type of sequential/dense/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n","TRT - VERBOSE\n","Running: MatMulToConvTransform on sequential/dense_1/MatMul\n","TRT - VERBOSE\n","Convert layer type of sequential/dense_1/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n","TRT - VERBOSE\n","Running: MatMulToConvTransform on sequential/dense_2/MatMul\n","TRT - VERBOSE\n","Convert layer type of sequential/dense_2/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n","TRT - VERBOSE\n","Running: MatMulToConvTransform on sequential/dense_3/MatMul\n","TRT - VERBOSE\n","Convert layer type of sequential/dense_3/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n","TRT - VERBOSE\n","Running: ShuffleShuffleFusion on sequential/flatten/Reshape\n","TRT - VERBOSE\n","ShuffleShuffleFusion: Fusing sequential/flatten/Reshape with reshape_before_sequential/dense/MatMul\n","TRT - VERBOSE\n","Running: ConvReshapeBiasAddFusion on sequential/dense/MatMul\n","TRT - VERBOSE\n","Running: ConvReshapeBiasAddFusion on sequential/dense_1/MatMul\n","TRT - VERBOSE\n","Running: ConvReshapeBiasAddFusion on sequential/dense_2/MatMul\n","TRT - VERBOSE\n","Running: ConvReshapeBiasAddFusion on sequential/dense_3/MatMul\n","TRT - VERBOSE\n","Applying ScaleNodes fusions.\n","TRT - VERBOSE\n","After scale fusion: 16 layers\n","TRT - VERBOSE\n","Running: SqueezePushDownFork on reshape_after_sequential/dense/MatMul\n","TRT - VERBOSE\n","-----------SqueezePushDown kSQUEEZE_FORK case: sequential/dense/MatMul --> reshape_after_sequential/dense/MatMul --> sequential/dense/Relu\n","TRT - VERBOSE\n","Running: SqueezePushDownFork on reshape_after_sequential/dense_1/MatMul\n","TRT - VERBOSE\n","-----------SqueezePushDown kSQUEEZE_FORK case: sequential/dense_1/MatMul --> reshape_after_sequential/dense_1/MatMul --> sequential/dense_1/Relu\n","TRT - VERBOSE\n","Running: SqueezePushDownFork on reshape_after_sequential/dense_2/MatMul\n","TRT - VERBOSE\n","-----------SqueezePushDown kSQUEEZE_FORK case: sequential/dense_2/MatMul --> reshape_after_sequential/dense_2/MatMul --> sequential/dense_2/Relu\n","TRT - VERBOSE\n","Running: ShuffleShuffleFusion on squeeze_after_sequential/dense/Relu\n","TRT - VERBOSE\n","ShuffleShuffleFusion: Fusing squeeze_after_sequential/dense/Relu with reshape_before_sequential/dense_1/MatMul\n","TRT - VERBOSE\n","Running: ShuffleShuffleFusion on squeeze_after_sequential/dense_1/Relu\n","TRT - VERBOSE\n","ShuffleShuffleFusion: Fusing squeeze_after_sequential/dense_1/Relu with reshape_before_sequential/dense_2/MatMul\n","TRT - VERBOSE\n","Running: ShuffleShuffleFusion on squeeze_after_sequential/dense_2/Relu\n","TRT - VERBOSE\n","ShuffleShuffleFusion: Fusing squeeze_after_sequential/dense_2/Relu with reshape_before_sequential/dense_3/MatMul\n","TRT - VERBOSE\n","Running: ConvReluFusion on sequential/dense/MatMul\n","TRT - VERBOSE\n","ConvReluFusion: Fusing sequential/dense/MatMul with sequential/dense/Relu\n","TRT - VERBOSE\n","Running: ShuffleErasure on squeeze_after_sequential/dense/Relu + reshape_before_sequential/dense_1/MatMul\n","TRT - VERBOSE\n","Removing squeeze_after_sequential/dense/Relu + reshape_before_sequential/dense_1/MatMul\n","TRT - VERBOSE\n","Running: ConvReluFusion on sequential/dense_1/MatMul\n","TRT - VERBOSE\n","ConvReluFusion: Fusing sequential/dense_1/MatMul with sequential/dense_1/Relu\n","TRT - VERBOSE\n","Running: ShuffleErasure on squeeze_after_sequential/dense_1/Relu + reshape_before_sequential/dense_2/MatMul\n","TRT - VERBOSE\n","Removing squeeze_after_sequential/dense_1/Relu + reshape_before_sequential/dense_2/MatMul\n","TRT - VERBOSE\n","Running: ConvReluFusion on sequential/dense_2/MatMul\n","TRT - VERBOSE\n","ConvReluFusion: Fusing sequential/dense_2/MatMul with sequential/dense_2/Relu\n","TRT - VERBOSE\n","Running: ShuffleErasure on squeeze_after_sequential/dense_2/Relu + reshape_before_sequential/dense_3/MatMul\n","TRT - VERBOSE\n","Removing squeeze_after_sequential/dense_2/Relu + reshape_before_sequential/dense_3/MatMul\n","TRT - VERBOSE\n","After dupe layer removal: 7 layers\n","TRT - VERBOSE\n","After final dead-layer removal: 7 layers\n","TRT - VERBOSE\n","After tensor merging: 7 layers\n","TRT - VERBOSE\n","After vertical fusions: 7 layers\n","TRT - VERBOSE\n","After dupe layer removal: 7 layers\n","TRT - VERBOSE\n","After final dead-layer removal: 7 layers\n","TRT - VERBOSE\n","After tensor merging: 7 layers\n","TRT - VERBOSE\n","After slice removal: 7 layers\n","TRT - VERBOSE\n","After concat removal: 7 layers\n","TRT - VERBOSE\n","Trying to split Reshape and strided tensor\n","TRT - VERBOSE\n","Graph construction and optimization completed in 0.0650899 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:226: DeprecationWarning: Use build_serialized_network instead.\n"]},{"output_type":"stream","name":"stdout","text":["TRT - VERBOSE\n","Using cublasLt as a tactic source\n","TRT - INFO\n","[MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +224, now: CPU 0, GPU 963 (MiB)\n","TRT - VERBOSE\n","Using cuDNN as a tactic source\n","TRT - INFO\n","[MemUsageChange] Init cuDNN: CPU +0, GPU +52, now: CPU 0, GPU 1015 (MiB)\n","TRT - WARNING\n","TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n","TRT - INFO\n","Local timing cache in use. Profiling results in this builder pass will not be stored.\n","TRT - VERBOSE\n","Constructing optimization profile number 0 [1/1].\n","TRT - VERBOSE\n","Reserving memory for host IO tensors. Host: 0 bytes\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(784,28,1,1) -> Float(784,1,28,28) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(input_1 -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 1.13362\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.033632\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.885952\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003ea Time: 0.033632\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(784,28,1,1) -> Float(28,28:32,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(input_1 -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0282631\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.845579\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0763573\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003e8 Time: 0.0282631\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(784,1,1,1) -> Float(784,1,784,784) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0307963\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0342112\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.193008\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003e8 Time: 0.0307963\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(784,1,784,784) -> Float(784,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.028648\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.03736\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0278898\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0278898\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(25,1:32,1,1) -> Float(784,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0272082\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0353173\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0282933\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003e8 Time: 0.0272082\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(25,1:32,1,1) -> Float(784,1,784,784) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0263171\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0348437\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0601109\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003e8 Time: 0.0263171\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(155,1,1,1) -> Float(155,1,155,155) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0317498\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.036912\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0281849\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0281849\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(155,1,155,155) -> Float(155,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.110053\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0324965\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0274018\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0274018\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0317634\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0313018\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0256624\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0256624\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0292782\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0399573\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0222784\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0222784\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(63,1,1,1) -> Float(63,1,63,63) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0243032\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0361781\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0293929\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003e8 Time: 0.0243032\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(63,1,63,63) -> Float(63,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0265042\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0378121\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0273945\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003e8 Time: 0.0265042\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","*************** Autotuning Reformat: Float(10,1,10,10) -> Float(10,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n","TRT - VERBOSE\n","Tactic: 0x00000000000003e8 Time: 0.0284667\n","TRT - VERBOSE\n","Tactic: 0x00000000000003ea Time: 0.0337248\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.628027\n","TRT - VERBOSE\n","Fastest Tactic: 0x00000000000003e8 Time: 0.0284667\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","=============== Computing reformatting costs\n","TRT - VERBOSE\n","=============== Computing costs for \n","TRT - VERBOSE\n","*************** Autotuning format combination: Float(784,28,1,1) -> Float(784,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.371339\n","TRT - VERBOSE\n","Tactic: 0x0000000000000001 Time: 0.0542766\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000001 Time: 0.0542766\n","TRT - VERBOSE\n",">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000001\n","TRT - VERBOSE\n","*************** Autotuning format combination: Float(784,1,28,28) -> Float(784,1,784,784) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0239756\n","TRT - VERBOSE\n","Tactic: 0x0000000000000001 Time: 0.0481752\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0239756\n","TRT - VERBOSE\n",">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n","TRT - VERBOSE\n","*************** Autotuning format combination: Float(28,28:32,1,1) -> Float(25,1:32,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0258765\n","TRT - VERBOSE\n","Tactic: 0x0000000000000001 Time: 0.0537691\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0258765\n","TRT - VERBOSE\n",">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n","TRT - VERBOSE\n","=============== Computing costs for \n","TRT - VERBOSE\n","*************** Autotuning format combination: Float(784,1,1,1) -> Float(155,1,1,1) ***************\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CudaDepthwiseConvolution)\n","TRT - VERBOSE\n","CudaDepthwiseConvolution has no valid tactics for this config, skipping\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (FusedConvActConvolution)\n","TRT - VERBOSE\n","FusedConvActConvolution has no valid tactics for this config, skipping\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CudnnConvolution)\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.142148\n","TRT - VERBOSE\n","Tactic: 0x0000000000000001 Time: 0.115783\n","TRT - VERBOSE\n","Tactic: 0x0000000000000002 Time: 0.194805\n","TRT - VERBOSE\n","Tactic: 0x0000000000000004 Time: 2.26822\n","TRT - VERBOSE\n","Tactic: 0x0000000000000005 Time: 0.292512\n","TRT - VERBOSE\n","Tactic: 0x0000000000000038 Time: 0.115449\n","TRT - VERBOSE\n","Tactic: 0x0000000000000039 Time: 0.0239627\n","TRT - VERBOSE\n","Tactic: 0x000000000000003a Time: 0.194773\n","TRT - VERBOSE\n","Tactic: 0x000000000000003c Time: 2.27017\n","TRT - VERBOSE\n","Tactic: 0x000000000000003d Time: 0.292693\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000039 Time: 0.0239627\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CublasConvolution)\n","TRT - VERBOSE\n","Tactic: 0x0000000000000000 Time: 0.0160899\n","TRT - VERBOSE\n","Tactic: 0x0000000000000001 Time: 0.0180149\n","TRT - VERBOSE\n","Fastest Tactic: 0x0000000000000000 Time: 0.0160899\n","TRT - VERBOSE\n","--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n","TRT - VERBOSE\n","sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x128_relu_interior_nn_v1 Tactic: 0x18597bd4a7d0164d\n","TRT - VERBOSE\n","Tactic: 0x18597bd4a7d0164d Time: 0.366944\n","TRT - VERBOSE\n","sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x128_relu_medium_nn_v1 Tactic: 0x195431d38ba5af88\n","TRT - VERBOSE\n","Tactic: 0x195431d38ba5af88 Time: 0.370005\n","TRT - VERBOSE\n","sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x25eed4cfa195d49d\n","TRT - VERBOSE\n","Tactic: 0x25eed4cfa195d49d Time: 0.234059\n","TRT - VERBOSE\n","sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x128_relu_small_nn_v1 Tactic: 0x365602d0613d4c36\n","TRT - VERBOSE\n","Tactic: 0x365602d0613d4c36 Time: 0.365909\n","TRT - VERBOSE\n","sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x5193693bc0732c65\n","TRT - VERBOSE\n","Deleting timing cache: 16 entries, served 0 hits since creation.\n","TRT - ERROR\n","1: Unexpected exception \n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-587d78f109a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m '''\n\u001b[1;32m     56\u001b[0m \u001b[0mTrtModelParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mTrtModelOptimizeAndSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fp32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mModelInferSetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-b98dc0f94ec7>\u001b[0m in \u001b[0;36mTrtModelOptimizeAndSerialize\u001b[0;34m(precision, calibPath, calibSet)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mserializedEngine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mengineFD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelOptName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'serialize'"]}]}]}