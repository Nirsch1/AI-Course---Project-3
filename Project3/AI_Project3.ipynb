{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81839b723d5f485790b41ff235b79c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53f68e30cc804068ac95c9bedf5130c7",
              "IPY_MODEL_f13b8264d2944cc29d422638302ed754"
            ],
            "layout": "IPY_MODEL_0a24766112fd4c1babcd1f2261d92c16"
          }
        },
        "53f68e30cc804068ac95c9bedf5130c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_892d177fe4aa458c97d8cda900289319",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d85a06cdd9254e50bea9b010f5047eba",
            "value": "0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "f13b8264d2944cc29d422638302ed754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d67dab404a24978b35eb31c128773ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0ff6c5659bf46cdb5147cd02bb9ab85",
            "value": 1
          }
        },
        "0a24766112fd4c1babcd1f2261d92c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892d177fe4aa458c97d8cda900289319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85a06cdd9254e50bea9b010f5047eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d67dab404a24978b35eb31c128773ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ff6c5659bf46cdb5147cd02bb9ab85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j-gilyQlVH5n"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "  !pip install turicreate\n",
        "  import turicreate as tc\n",
        "  import os\n",
        "  try:\n",
        "    del os.environ['LC_ALL']\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --index-url https://pypi.ngc.nvidia.com nvidia-tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi0PiD5Qd5vE",
        "outputId": "514922f7-b213-447c-d1c1-ddf99f6ab530"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.ngc.nvidia.com, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-tensorrt/nvidia_tensorrt-8.4.1.5-cp37-none-linux_x86_64.whl (774.4 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 774.4 MB 17 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cuda-runtime-cu11/nvidia-cuda-runtime-cu11-2022.4.25.tar.gz (16 kB)\n",
            "Collecting nvidia-cublas-cu11\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cublas-cu11/nvidia-cublas-cu11-2022.4.8.tar.gz (16 kB)\n",
            "Collecting nvidia-cudnn-cu11\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cudnn-cu11/nvidia-cudnn-cu11-2022.5.19.tar.gz (16 kB)\n",
            "Collecting nvidia-cublas-cu117\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cublas-cu117/nvidia_cublas_cu117-11.10.1.25-py3-none-manylinux1_x86_64.whl (333.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333.1 MB 33 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (57.4.0)\n",
            "Collecting nvidia-cuda-runtime-cu117\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cuda-runtime-cu117/nvidia_cuda_runtime_cu117-11.7.60-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849 kB 47.8 MB/s \n",
            "\u001b[?25hCollecting nvidia-cudnn-cu116\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cudnn-cu116/nvidia_cudnn_cu116-8.4.0.27-py3-none-manylinux1_x86_64.whl (719.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 719.3 MB 18 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-cublas-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11\n",
            "  Building wheel for nvidia-cublas-cu11 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-cublas-cu11: filename=nvidia_cublas_cu11-2022.4.8-py3-none-any.whl size=15624 sha256=85629b8c9436b6a49002075a506352164c30bb5c66e8311f93fb089d93d00150\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/c3/94/1ffd5bac267cfdc2b222a4ec6915278ef18a028a916b9a5ac3\n",
            "  Building wheel for nvidia-cuda-runtime-cu11 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-cuda-runtime-cu11: filename=nvidia_cuda_runtime_cu11-2022.4.25-py3-none-any.whl size=15696 sha256=330e345d4144b4c0d2f0b3c878902464a9768260efea5dc740fe20612192a5cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/fe/2b/e553db7867508b2268b14ac194e9ac5b3f51f21316c282c96c\n",
            "  Building wheel for nvidia-cudnn-cu11 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-cudnn-cu11: filename=nvidia_cudnn_cu11-2022.5.19-py3-none-any.whl size=15617 sha256=8ea1df6cd0e19359b566c542a3e2de5fab683c26d4c96e58632e37a70b1ec421\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/32/69/9787704b5f889217708864db5e00812c8c1c349ef89084c59c\n",
            "Successfully built nvidia-cublas-cu11 nvidia-cuda-runtime-cu11 nvidia-cudnn-cu11\n",
            "Installing collected packages: nvidia-cudnn-cu116, nvidia-cuda-runtime-cu117, nvidia-cublas-cu117, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-tensorrt\n",
            "Successfully installed nvidia-cublas-cu11-2022.4.8 nvidia-cublas-cu117-11.10.1.25 nvidia-cuda-runtime-cu11-2022.4.25 nvidia-cuda-runtime-cu117-11.7.60 nvidia-cudnn-cu11-2022.5.19 nvidia-cudnn-cu116-8.4.0.27 nvidia-tensorrt-8.4.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TensorRTUtils:**"
      ],
      "metadata": {
        "id": "t0-7SeTwQje7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorRTUtils\n",
        "!pip install pycuda\n",
        "!pip install tensorrt\n",
        "import tensorrt as trt\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class HostDeviceMem(object):\n",
        "    def __init__(self, host_mem, device_mem):\n",
        "        self.host = host_mem\n",
        "        self.device = device_mem\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "class ErrorRecorder(trt.IErrorRecorder):\n",
        "    def __init__(self):\n",
        "        trt.IErrorRecorder.__init__(self)\n",
        "        self.errorsStack = []\n",
        "\n",
        "    def clear(self):\n",
        "        self.errorsStack.clear()\n",
        "    def get_error_code(self, arg0):\n",
        "        #Error code saved in the error tuple first position\n",
        "        return self.errorsStack[arg0][0]\n",
        "    def get_error_desc(self, arg0):\n",
        "        # Error code saved in the error tuple second position\n",
        "        return self.errorsStack[arg0][1]\n",
        "    def has_overflowed(self):\n",
        "        return False\n",
        "    def num_errors(self):\n",
        "        return len(self.errorsStack)\n",
        "    def report_error(self, arg0, arg1):\n",
        "        error = (arg0, arg1)\n",
        "        #Errors will be saved as a list of tuples, each tuple will be a pair of error code and error description\n",
        "        self.errorsStack.append(error)\n",
        "\n",
        "class Logger(trt.ILogger):\n",
        "    def __init__(self):\n",
        "        trt.ILogger.__init__(self)\n",
        "\n",
        "    def log(self, severity, msg):\n",
        "        if severity == trt.ILogger.INTERNAL_ERROR:\n",
        "            print('INTERNAL_ERROR')\n",
        "        elif severity == trt.ILogger.ERROR:\n",
        "            print('TRT - ERROR')\n",
        "        elif severity == trt.ILogger.WARNING:\n",
        "            print('TRT - WARNING')\n",
        "        elif severity == trt.ILogger.INFO:\n",
        "            print('TRT - INFO')\n",
        "        elif severity == trt.ILogger.VERBOSE:\n",
        "            print('TRT - VERBOSE')\n",
        "        else:\n",
        "            print('TRT - Wrong severity')\n",
        "\n",
        "        print(msg)\n",
        "\n",
        "class Int8EntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
        "    def __init__(self, calibrationSetPath = None, calibSet = None):\n",
        "        # Whenever you specify a custom constructor for a TensorRT class,\n",
        "        # you MUST call the constructor of the parent explicitly.\n",
        "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
        "\n",
        "        self.cacheFile = calibrationSetPath + '/CacheFile.bin'\n",
        "        self.batchSize = 1\n",
        "        self.currentIndex = 0\n",
        "        self.deviceInput = None\n",
        "        self.currentIndex = 0\n",
        "        self.PreProcessedSetPath = calibrationSetPath + '/PreProcessedSet'\n",
        "        self.PreProcessedSetCount = calibSet.n\n",
        "        self.PreProcessedSize = calibSet[0][0].size * 4 #float\n",
        "        self.currentIndex = 0\n",
        "\n",
        "        # Allocate enough memory for a whole batch.\n",
        "        self.deviceInput = cuda.mem_alloc(self.PreProcessedSize)\n",
        "\n",
        "        if os.path.exists(self.cacheFile):\n",
        "            print('Calibration cache file is already exist - ', self.cacheFile)\n",
        "            return\n",
        "\n",
        "        filesCnt = os.listdir(self.PreProcessedSetPath)\n",
        "\n",
        "        if len(filesCnt) == self.PreProcessedSetCount:\n",
        "            print('ERROR - Pre processed file set is exist!!!')\n",
        "            return\n",
        "\n",
        "        if self.PreProcessedSetCount == 0:\n",
        "            print('ERROR - Calibration set is empty!!!')\n",
        "\n",
        "        print('Start calibration batches build')\n",
        "\n",
        "        for idx in range(self.PreProcessedSetCount):\n",
        "            preProcImg, label = calibSet.next()\n",
        "            preProcessedFile = open(self.PreProcessedSetPath + '/' + str(idx) + '.bin', mode='wb')\n",
        "            preProcImg.tofile(preProcessedFile)\n",
        "            preProcessedFile.close()\n",
        "\n",
        "        print('End calibration batches build')\n",
        "\n",
        "    def get_algorithm(self):\n",
        "        return trt.CalibrationAlgoType.ENTROPY_CALIBRATION_2\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batchSize\n",
        "\n",
        "    # TensorRT passes along the names of the engine bindings to the get_batch function.\n",
        "    # You don't necessarily have to use them, but they can be useful to understand the order of\n",
        "    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n",
        "    def get_batch(self, names):\n",
        "        if not self.currentIndex < self.PreProcessedSetCount:\n",
        "            return None\n",
        "\n",
        "        print('Get pre processed file index - ', not self.currentIndex)\n",
        "\n",
        "        batchData = np.fromfile(self.PreProcessedSetPath + '/' + str(self.currentIndex) + '.bin', dtype=np.single)\n",
        "        cuda.memcpy_htod(self.deviceInput, batchData)\n",
        "        self.currentIndex += 1\n",
        "\n",
        "        return [self.deviceInput]\n",
        "\n",
        "    def read_calibration_cache(self):\n",
        "        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n",
        "        if os.path.exists(self.cacheFile):\n",
        "            with open(self.cacheFile, \"rb\") as f:\n",
        "                return f.read()\n",
        "\n",
        "    def write_calibration_cache(self, cache):\n",
        "        with open(self.cacheFile, \"wb\") as f:\n",
        "            f.write(cache)\n",
        "\n",
        "logger = Logger()\n",
        "errorRecorder = ErrorRecorder()\n",
        "\n",
        "builder = trt.Builder(logger)\n",
        "builder.max_batch_size = 1\n",
        "\n",
        "calib = None\n",
        "config = builder.create_builder_config()\n",
        "config.max_workspace_size = 1073741824\n",
        "\n",
        "optimizationProfiler = builder.create_optimization_profile()\n",
        "\n",
        "networkFlags = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
        "network = builder.create_network(networkFlags)\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "runtime = trt.Runtime(logger)\n",
        "\n",
        "engine = None\n",
        "context = None\n",
        "\n",
        "modelName = None\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "bindings = []\n",
        "stream = None\n",
        "\n",
        "def TrtModelParse(modelPath):\n",
        "    global modelName\n",
        "    global parser\n",
        "    global network\n",
        "\n",
        "    modelName = modelPath.split('.')[0]\n",
        "    parseResult = parser.parse_from_file(modelPath)\n",
        "\n",
        "    if (not parseResult):\n",
        "        for error in range(parser.num_errors):\n",
        "            print(str(parser.get_error(error)))\n",
        "    else:\n",
        "        print(\"Model parsing OK!\")\n",
        "\n",
        "        print(\"Network Description\")\n",
        "\n",
        "        inputs = [network.get_input(i) for i in range(network.num_inputs)]\n",
        "        outputs = [network.get_output(i) for i in range(network.num_outputs)]\n",
        "\n",
        "        for input in inputs:\n",
        "            print(\"Input '{}' with shape {} and dtype {}\".format(input.name, input.shape, input.dtype))\n",
        "        for output in outputs:\n",
        "            print(\"Output '{}' with shape {} and dtype {}\".format(output.name, output.shape, output.dtype))\n",
        "\n",
        "def TrtModelOptimizeAndSerialize(precision = 'fp32',calibPath=\"\", calibSet=None):\n",
        "    global modelName\n",
        "    global builder\n",
        "    global optimizationProfiler\n",
        "    global calib\n",
        "    global config\n",
        "    global network\n",
        "    global engine\n",
        "    global runtime\n",
        "\n",
        "    modelOptName = modelName + precision + '.trt.engine'\n",
        "\n",
        "    if os.path.exists(modelOptName):\n",
        "        with open(modelOptName, 'rb') as f:\n",
        "            engine = runtime.deserialize_cuda_engine(f.read())\n",
        "    else:\n",
        "        inputs = [network.get_input(i) for i in range(network.num_inputs)]\n",
        "        input = network.get_input(0)\n",
        "\n",
        "        inputShape = [1, input.shape[1], input.shape[2], input.shape[3]]\n",
        "\n",
        "        optimizationProfiler.set_shape(input.name, inputShape, inputShape, inputShape)\n",
        "\n",
        "        config.add_optimization_profile(optimizationProfiler)\n",
        "\n",
        "        if precision == 'fp16':\n",
        "            if builder.platform_has_fast_fp16:\n",
        "                config.set_flag(trt.BuilderFlag.FP16)\n",
        "        elif precision == 'int8':\n",
        "            if builder.platform_has_fast_int8:\n",
        "                if builder.platform_has_fast_fp16:\n",
        "                    # Also enable fp16, as some layers may be even more efficient in fp16 than int8\n",
        "                    config.set_flag(trt.BuilderFlag.FP16)\n",
        "\n",
        "                config.set_flag(trt.BuilderFlag.INT8)\n",
        "\n",
        "                calib = Int8EntropyCalibrator(calibPath, calibSet)\n",
        "                config.int8_calibrator = calib\n",
        "\n",
        "        engine = builder.build_engine(network, config)\n",
        "\n",
        "        serializedEngine = engine.serialize()\n",
        "\n",
        "        engineFD = open(modelOptName, 'wb')\n",
        "        engineFD.write(serializedEngine)\n",
        "        engineFD.close()\n",
        "\n",
        "    print('TRT engine - ', engine.device_memory_size, ' Bytes')\n",
        "    engineDeviceMemory = 0\n",
        "    engineDeviceMemory += engine.device_memory_size\n",
        "    print('TRT engine number of layers - ', engine.num_layers)\n",
        "    print('TRT engine number of bindings - ', engine.num_bindings)\n",
        "    print('TRT engine number of profils - ', engine.num_optimization_profiles)\n",
        "\n",
        "    print('Completion optimized model')\n",
        "\n",
        "def ModelInferSetup():\n",
        "    global context\n",
        "    global engine\n",
        "    global inputs\n",
        "    global outputs\n",
        "    global bindings\n",
        "    global stream\n",
        "\n",
        "    stream = cuda.Stream()\n",
        "\n",
        "    #Over all Tensors inputs & outputs of the TRT engine\n",
        "    #TRT hold first all Tensors inputs and after the Tensor outptus\n",
        "    for binding in engine:\n",
        "        #Get current binded Tensor volume size in elemente units\n",
        "        size = trt.volume(engine.get_binding_shape(binding))\n",
        "        #Get current binded Tensor element type\n",
        "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
        "        # Allocate host page locked bbuffer\n",
        "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
        "        # Allocate device bbuffer\n",
        "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
        "        # Append the device buffer to device bindings.\n",
        "        bindings.append(int(device_mem))\n",
        "        # Append to the appropriate list.\n",
        "        if engine.binding_is_input(binding):\n",
        "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "        else:\n",
        "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "\n",
        "    # Contexts are used to perform inference.\n",
        "    context = engine.create_execution_context()\n",
        "    context.error_recorder = errorRecorder\n",
        "\n",
        "def Inference(externalnputs = None):\n",
        "\n",
        "    global context\n",
        "    global stream\n",
        "    global inputs\n",
        "    global outputs\n",
        "    global bindings\n",
        "\n",
        "    try:\n",
        "        #verify that TRT context generated successfully\n",
        "        if context is not None:\n",
        "            #Verify that inputs to inference are exist\n",
        "            if externalnputs is not None:\n",
        "                #Copy all Tensors inputs data from user memory to TRT host page locked memory before loading it to the device\n",
        "                if len(externalnputs) == len(inputs):\n",
        "                    for index in range(len(externalnputs)):\n",
        "                        if len(inputs[index].host) == externalnputs[index].size:\n",
        "                            np.copyto(inputs[index].host, externalnputs[index].ravel())\n",
        "                        else:\n",
        "                            print('TRT external input size - ', externalnputs[index].size,\n",
        "                                  ' is not equal to model inputs size - ', len(inputs[index].host))\n",
        "                            return None\n",
        "\n",
        "                    # Transfer input data to the GPU from the host page locked memory.\n",
        "                    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
        "                    # Run asynchronously inference using the user\\internal stream.\n",
        "                    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
        "                    # Transfer predictions back from the GPU.\n",
        "                    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
        "\n",
        "                    stream.synchronize()\n",
        "                    # Build a list of Tensors outputs and return only the host outputs.\n",
        "                    return [out.host for out in outputs]\n",
        "                else:\n",
        "                    print('External inputs list size - ', len(externalnputs), ' is not equal to model inputs list size - ', len(inputs))\n",
        "                    return None\n",
        "            else:\n",
        "                print('External inputs list is None ERROR')\n",
        "                return None\n",
        "    except BaseException as e:\n",
        "        msg = e\n",
        "        print('TRT inference exception ERROR - ', msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzctBFwmVnAo",
        "outputId": "4692ea60-52ac-47b4-b09d-70751b5ba648"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRT - INFO\n",
            "The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
            "\n",
            "TRT - INFO\n",
            "[MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 0, GPU 1211 (MiB)\n",
            "TRT - INFO\n",
            "[MemUsageChange] Init builder kernel library: CPU +0, GPU +68, now: CPU 0, GPU 1279 (MiB)\n",
            "TRT - INFO\n",
            "The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
            "\n",
            "TRT - INFO\n",
            "[MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 0, GPU 1279 (MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:144: DeprecationWarning: Use set_memory_pool_limit instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **onnxUtils:**"
      ],
      "metadata": {
        "id": "2cyDtE0LQrOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# onnxUtils\n",
        "!pip install tf2onnx onnx onnxsim\n",
        "import json\n",
        "import time\n",
        "import tf2onnx\n",
        "import onnx\n",
        "#import onnxsim\n",
        "import os.path\n",
        "\n",
        "\n",
        "# Save model into h5 and ONNX formats\n",
        "def convertKerasToONNX(name, model, overwrite_existing = False):\n",
        "    modelFile = name + '.onnx'\n",
        "    if not os.path.isfile(modelFile) or overwrite_existing:\n",
        "        # Save model with ONNX format\n",
        "        (onnx_model_proto, storage) = tf2onnx.convert.from_keras(model)\n",
        "        with open(os.path.join(modelFile), \"wb\") as f:\n",
        "            f.write(onnx_model_proto.SerializeToString())\n",
        "            f.close()\n",
        "    \n",
        "    return modelFile, onnx_model_proto, storage\n",
        "\n",
        "def ModelOnnxCheck(name):\n",
        "\n",
        "    msg = 'OK'\n",
        "    isCheckOk = True\n",
        "\n",
        "    print(\"===============================================================\")\n",
        "    print(\"Onnx model check report:\")\n",
        "\n",
        "    try:\n",
        "        # Perform basic check on the model input\n",
        "        onnx.checker.check_model(name + '.onnx')\n",
        "        isCheckOk = True\n",
        "    except onnx.checker.ValidationError as e:\n",
        "        msg = e\n",
        "        isCheckOk=False\n",
        "    except BaseException as e:\n",
        "        msg = e\n",
        "        isCheckOk=False\n",
        "\n",
        "    if isCheckOk:\n",
        "        print('Model check completed Successfully')\n",
        "    else:\n",
        "        print('ERROR - Model check failure')\n",
        "\n",
        "    print('Model onnx checker, check model - ', msg)\n",
        "\n",
        "    return isCheckOk\n",
        "\n",
        "def RemoveInitializerFromInput(model, modelPath):\n",
        "    modelGraphInputs = model.graph.input\n",
        "    startInputsCount = len(modelGraphInputs)\n",
        "\n",
        "    nameToInput = {}\n",
        "    for input in modelGraphInputs:\n",
        "        nameToInput[input.name] = input\n",
        "\n",
        "    for initializer in model.graph.initializer:\n",
        "        if initializer.name in nameToInput:\n",
        "            modelGraphInputs.remove(nameToInput[initializer.name])\n",
        "\n",
        "    endInputsCount = len(modelGraphInputs)\n",
        "\n",
        "    if startInputsCount != endInputsCount:\n",
        "        print('Model includes several Initializers which considered as inputs to the graph - ', startInputsCount - endInputsCount)\n",
        "        print('All Initializers were removed from graph inputs')\n",
        "        print('Replace the model *.onx file with the updated one')\n",
        "        onnx.save(model, modelPath)\n",
        "\n",
        "def ProcessModelInputs(model, modelPath):\n",
        "    RemoveInitializerFromInput(model, modelPath)\n",
        "    modelGraphInputs = model.graph.input\n",
        "\n",
        "    modelInputsDims = {}\n",
        "    modelDynamicInputsDict = {}\n",
        "    modelInputs = modelGraphInputs\n",
        "    modelInputsNames = []\n",
        "    print(str(modelInputs))\n",
        "\n",
        "    for tensorInput in modelInputs:\n",
        "        isInputDynamic = False\n",
        "        modelDynamicInputShape = []\n",
        "        for dim in tensorInput.type.tensor_type.shape.dim:\n",
        "            if dim.dim_value == 0:\n",
        "                isInputDynamic = True\n",
        "                print('CAUTION!!! - Tensor input name' + ' - ', tensorInput.name, ', dimension - ' , dim.dim_param, ', set its value to 1 for Onnx simplify operation')\n",
        "                modelDynamicInputShape.append(1)\n",
        "            else:\n",
        "                modelDynamicInputShape.append(dim.dim_value)\n",
        "\n",
        "        modelInputsNames.append(tensorInput.name)\n",
        "\n",
        "        if isInputDynamic is True:\n",
        "            modelDynamicInputsDict[tensorInput.name] = modelDynamicInputShape\n",
        "\n",
        "    return modelDynamicInputsDict\n",
        "\n",
        "def ModelSimplify(name):\n",
        "\n",
        "    msg = 'OK'\n",
        "    nameSimp = name + 'Simp'\n",
        "    model = None\n",
        "    isSimplifiedOK = True\n",
        "\n",
        "    if os.path.exists(nameSimp + '.onnx'):\n",
        "        print('Model Onnx simplify is already exist, No model check and\\or simplify operations is required')\n",
        "        model = onnx.load(nameSimp + '.onnx')\n",
        "        isSimplifiedOK = True\n",
        "    else:\n",
        "        print(\"===============================================================\")\n",
        "        print(\"Onnx model simplifier report:\")\n",
        "        model = onnx.load(name + '.onnx')\n",
        "\n",
        "        modelDynamicInputsDict = ProcessModelInputs(model, name + '.onnx')\n",
        "\n",
        "        try:\n",
        "            print('Start model onnx simplify...')\n",
        "            # Perform simplification on the model input\n",
        "            model, check = onnxsim.simplify(model,input_shapes=modelDynamicInputsDict,\n",
        "                                                  dynamic_input_shape=(len(modelDynamicInputsDict) > 0))\n",
        "            print('Completion model onnx simplify')\n",
        "            if (check):\n",
        "                isSimplifiedOK = True\n",
        "                print('Onnx simplification success!')\n",
        "                print('Save Onnx simplified model to - ', nameSimp + '.onnx')\n",
        "                onnx.save(model, nameSimp + '.onnx')\n",
        "            else:\n",
        "                isSimplifiedOK = False\n",
        "                print('Onnx simplification failure!')\n",
        "                print('Simplified Onnx model could not be generated and validated')\n",
        "        except BaseException as e:\n",
        "            print('Onnx simplification exception - ', e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU_AzfphVoRZ",
        "outputId": "ded3dafd-f010-4068-c6da-f12fffa6d021"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.12.0-py3-none-any.whl (442 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 442 kB 35.2 MB/s \n",
            "\u001b[?25hCollecting onnx\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.1 MB 62.1 MB/s \n",
            "\u001b[?25hCollecting onnxsim\n",
            "  Downloading onnxsim-0.4.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (2.23.0)\n",
            "Collecting flatbuffers~=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n",
            "Collecting rich\n",
            "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->onnxsim) (2.6.1)\n",
            "Installing collected packages: commonmark, rich, onnx, flatbuffers, tf2onnx, onnxsim\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "Successfully installed commonmark-0.9.1 flatbuffers-1.12 onnx-1.12.0 onnxsim-0.4.7 rich-12.5.1 tf2onnx-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **wandb_helpers:**"
      ],
      "metadata": {
        "id": "Yuy6_TxZQvKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb_helpers\n",
        "!pip install wandb\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "Dataset = namedtuple(\"Dataset\", [\"images\", \"labels\"])\n",
        "dataset_names = [\"training\", \"validation\", \"test\"]\n",
        "\n",
        "def start_wandb_run(model_name, config):\n",
        "    timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "    return wandb.init(project=f\"ml-p2\", entity=\"ml-p2\", name=f\"{model_name}-{timestamp}\" , \n",
        "        notes = f\"Training FCNN model @{timestamp}\", config = config)\n",
        "\n",
        "def read_datasets(wandb_run, dataset_tag = \"latest\"):\n",
        "    '''\n",
        "    Read all datasets from W&B.\n",
        "    Usage example: train_set, validation_set, test_set = wbh.read_datasets(run)\n",
        "    '''\n",
        "    artifact = wandb_run.use_artifact(f'ml-p2/ml-p2/fashion-mnist:{dataset_tag}', type='dataset')\n",
        "    data_dir = artifact.download()\n",
        "    return [ read_dataset(data_dir, ds_name) for ds_name in dataset_names ]\n",
        "\n",
        "def read_dataset(data_dir, ds_name):\n",
        "    filename = ds_name + \".npz\"\n",
        "    data = np.load(os.path.join(data_dir, filename))\n",
        "    return Dataset(images = data[\"x\"], labels = data[\"y\"])\n",
        "\n",
        "def read_model(wandb_run, model_name, model_tag = \"latest\") -> tf.keras.models.Model:\n",
        "    artifact = wandb_run.use_artifact(f'ml-p2/ml-p2/{model_name}:{model_tag}', type='model')\n",
        "    artifact_dir = artifact.download()\n",
        "    return tf.keras.models.load_model(artifact_dir)\n",
        "\n",
        "def save_model(wandb_run, model, config, model_name, model_description):\n",
        "    model_file = f'./saved-models/{model_name}.tf'\n",
        "    tf.keras.models.save_model(model, model_file)\n",
        "    model_artifact = wandb.Artifact(model_name, type = \"model\", description=model_description, metadata= dict(config))\n",
        "    model_artifact.add_dir(model_file)\n",
        "    wandb_run.log_artifact(model_artifact)\n",
        "\n",
        "def load_best_model(sweep_id):\n",
        "    api = wandb.Api()\n",
        "    sweep = api.sweep(f\"ml-p2/ml-p2/{sweep_id}\")\n",
        "    runs = sorted(sweep.runs,\n",
        "        key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)\n",
        "    val_acc = runs[0].summary.get(\"val_accuracy\", 0)\n",
        "    print(f\"Best run {runs[0].name} with {val_acc} validation accuracy\")\n",
        "\n",
        "    model_file = runs[0].file(\"model-best.h5\").download(replace=True)\n",
        "    model_file.close()\n",
        "\n",
        "#if (__name__ == \"__main__\"):\n",
        "#    load_best_model(\"6zmewzd0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_iT8JNVVobY",
        "outputId": "78c96da3-32ae-4aed-e36a-2e69062c1fe1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.1-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 70.4 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181 kB 72.8 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 51.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 77.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 76.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 72.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156 kB 68.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=41bbed3e87d29447da647571f1cac3c30f7d967f14ccf481a6cac029ebf4a9a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **trt-inference:**"
      ],
      "metadata": {
        "id": "HynoQt2cQzkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trt-inference\n",
        "#!pip install sklearn -qqq\n",
        "\n",
        "#from TensorRTUtils import *\n",
        "#from onnxUtils import convertKerasToONNX\n",
        "#import wandb_helpers as wbh\n",
        "\n",
        "import time\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "import tensorrt as trt\n",
        "import onnx\n",
        "import tf2onnx\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "import os\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt     \n",
        "\n",
        "modelName = \"FCNN\"\n",
        "\n",
        "'''\n",
        "Stage 1: Load an existing model\n",
        "===============================\n",
        "In this part we load the model we created in the previous project\n",
        "which is built to infer from FASHION-MNIST images.\n",
        "It is not a sofisticated model, but the idea to use something we\n",
        "know.\n",
        "'''\n",
        "dataset_path = '.\\\\artifacts\\\\fashion-mnist-v2'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    with start_wandb_run(\"FCNN-metrics\", None) as run:\n",
        "        train_set, validation_set, test_set = read_datasets(run)\n",
        "        model = read_model(run, \"FCNN\", \"latest\")\n",
        "else:\n",
        "    test_set = read_dataset('.\\\\artifacts\\\\fashion-mnist-v2', 'test')\n",
        "    model = tf.keras.models.load_model('.\\\\artifacts\\\\FCNN-v3')\n",
        "\n",
        "'''\n",
        "Stage 2: Convert to ONNX\n",
        "========================\n",
        "Convert the model to ONNX and save it to a file. This will allow\n",
        "us to load the model into a tensor-rt engine.\n",
        "'''\n",
        "modelFile, _, _ = convertKerasToONNX(modelName, model, True)\n",
        "\n",
        "'''\n",
        "Stage 3: Create the tensor-rt engine\n",
        "====================================\n",
        "Now that we a model file, we can load it into a \n",
        "tensor rt engine.\n",
        "We use FP 32 precision.\n",
        "'''\n",
        "TrtModelParse(modelFile)\n",
        "#TrtModelOptimizeAndSerialize(precision='fp32')\n",
        "TrtModelOptimizeAndSerialize(precision='fp16')\n",
        "ModelInferSetup()\n",
        "\n",
        "'''\n",
        "Stage 4: Inference\n",
        "==================\n",
        "Now the model is ready for inference. The model is executed several\n",
        "times on different images from the test set we've loaded on Stage 1\n",
        "'''\n",
        "inputs = []\n",
        "\n",
        "startTimeCpu = time.time()\n",
        "for i in range(len(test_set)):\n",
        "    img = test_set.images[i]\n",
        "    lbl = test_set.labels[i]\n",
        "    inputs.append(img)\n",
        "    outputsTrt = Inference(externalnputs=inputs)\n",
        "    #print(' topClassIdx - ', np.argmax(outputsTrt[0]))\n",
        "    inputs.clear()\n",
        "    \n",
        "    \n",
        "endTimeCpu = time.time()\n",
        "\n",
        "# total time taken\n",
        "averageTime = (endTimeCpu - startTimeCpu) / 1e-3 / len(test_set)\n",
        "print(f\"TRT Keras inference average time is: {averageTime} milliseconds\")\n",
        "print(f\"TRT Keras inference average FPS is: {1000 / averageTime}\")\n",
        "\n",
        "# Perform the DlewareAnalyzer inference with TRT & ORT\n",
        "\n",
        "#np.testing.assert_allclose(kerasPredictions, onnxPredictions[0], rtol=0, atol=1e-05, err_msg='Keras Vs. Onnx Failure!!!')\n",
        "\n",
        "\n",
        "#y_test = np.argmax(test_set.labels)\n",
        "# predictions = model.predict(test_set.images)\n",
        "# y_test = np.argmax(predictions, axis = 1)\n",
        "# print (classification_report(test_set.labels, y_test))\n",
        "# cm = confusion_matrix(test_set.labels, y_test)\n",
        "\n",
        "# class_names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "\n",
        "# ax = plt.subplot()\n",
        "# h = sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "# # labels, title and ticks\n",
        "# ax.set_xlabel('Predicted labels')\n",
        "# ax.set_ylabel('True labels')\n",
        "# ax.set_title('Confusion Matrix')\n",
        "# ax.xaxis.set_ticklabels(class_names)\n",
        "# ax.yaxis.set_ticklabels(class_names)\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "81839b723d5f485790b41ff235b79c78",
            "53f68e30cc804068ac95c9bedf5130c7",
            "f13b8264d2944cc29d422638302ed754",
            "0a24766112fd4c1babcd1f2261d92c16",
            "892d177fe4aa458c97d8cda900289319",
            "d85a06cdd9254e50bea9b010f5047eba",
            "0d67dab404a24978b35eb31c128773ae",
            "d0ff6c5659bf46cdb5147cd02bb9ab85"
          ]
        },
        "id": "EEa4aCwOWALB",
        "outputId": "8da0d651-2fec-4cdb-bf38-715b708267aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnirsch\u001b[0m (\u001b[33mml-p2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220817_074300-1bnp3w9b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ml-p2/ml-p2/runs/1bnp3w9b\" target=\"_blank\">FCNN-metrics-074300</a></strong> to <a href=\"https://wandb.ai/ml-p2/ml-p2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact fashion-mnist:latest, 418.77MB. 3 files... Done. 0:0:0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81839b723d5f485790b41ff235b79c78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">FCNN-metrics-074300</strong>: <a href=\"https://wandb.ai/ml-p2/ml-p2/runs/1bnp3w9b\" target=\"_blank\">https://wandb.ai/ml-p2/ml-p2/runs/1bnp3w9b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220817_074300-1bnp3w9b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRT - INFO\n",
            "----------------------------------------------------------------\n",
            "TRT - INFO\n",
            "Input filename:   FCNN.onnx\n",
            "TRT - INFO\n",
            "ONNX IR version:  0.0.7\n",
            "TRT - INFO\n",
            "Opset version:    13\n",
            "TRT - INFO\n",
            "Producer name:    tf2onnx\n",
            "TRT - INFO\n",
            "Producer version: 1.12.0 a58786\n",
            "TRT - INFO\n",
            "Domain:           \n",
            "TRT - INFO\n",
            "Model version:    0\n",
            "TRT - INFO\n",
            "Doc string:       \n",
            "TRT - INFO\n",
            "----------------------------------------------------------------\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::GridAnchor_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::GridAnchorRect_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::NMS_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::Reorg_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::Region_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::Clip_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::LReLU_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::PriorBox_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::Normalize_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::ScatterND version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::RPROI_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::BatchedNMS_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::BatchTilePlugin_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::FlattenConcat_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::CropAndResize version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::CropAndResizeDynamic version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::DetectionLayer_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::EfficientNMS_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::ProposalDynamic version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::Proposal version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::ProposalLayer_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::PyramidROIAlign_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::ResizeNearest_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::Split version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::SpecialSlice_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::InstanceNormalization_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::InstanceNormalization_TRT version 2\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::CoordConvAC version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::DecodeBbox3DPlugin version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::GenerateDetection_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::MultilevelProposeROI_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::NMSDynamic_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::PillarScatterPlugin version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::VoxelGeneratorPlugin version 1\n",
            "TRT - VERBOSE\n",
            "Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
            "TRT - VERBOSE\n",
            "Adding network input: input_1 with dtype: float32, dimensions: (-1, 28, 28, 1)\n",
            "TRT - VERBOSE\n",
            "Registering tensor: input_1 for ONNX tensor: input_1\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense_3/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense_3/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense_2/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense_2/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense_1/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense_1/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: sequential/dense/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Importing initializer: const_fold_opt__14\n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/flatten/Reshape [Reshape]\n",
            "TRT - VERBOSE\n",
            "Searching for input: input_1\n",
            "TRT - VERBOSE\n",
            "Searching for input: const_fold_opt__14\n",
            "TRT - VERBOSE\n",
            "sequential/flatten/Reshape [Reshape] inputs: [input_1 -> (-1, 28, 28, 1)[FLOAT]], [const_fold_opt__14 -> (2)[INT32]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/flatten/Reshape for ONNX node: sequential/flatten/Reshape\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/flatten/Reshape:0 for ONNX tensor: sequential/flatten/Reshape:0\n",
            "TRT - VERBOSE\n",
            "sequential/flatten/Reshape [Reshape] outputs: [sequential/flatten/Reshape:0 -> (-1, 784)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense/MatMul [MatMul]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/flatten/Reshape:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul [MatMul] inputs: [sequential/flatten/Reshape:0 -> (-1, 784)[FLOAT]], [sequential/dense/MatMul/ReadVariableOp:0 -> (784, 155)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense/MatMul for ONNX node: sequential/dense/MatMul\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense/MatMul:0 for ONNX tensor: sequential/dense/MatMul:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul [MatMul] outputs: [sequential/dense/MatMul:0 -> (-1, 155)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense/BiasAdd [Add]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense/MatMul:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense/BiasAdd [Add] inputs: [sequential/dense/MatMul:0 -> (-1, 155)[FLOAT]], [sequential/dense/BiasAdd/ReadVariableOp:0 -> (155)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense/BiasAdd for ONNX node: sequential/dense/BiasAdd\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense/BiasAdd:0 for ONNX tensor: sequential/dense/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense/BiasAdd [Add] outputs: [sequential/dense/BiasAdd:0 -> (-1, 155)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense/Relu [Relu]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense/Relu [Relu] inputs: [sequential/dense/BiasAdd:0 -> (-1, 155)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense/Relu for ONNX node: sequential/dense/Relu\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense/Relu:0 for ONNX tensor: sequential/dense/Relu:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense/Relu [Relu] outputs: [sequential/dense/Relu:0 -> (-1, 155)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_1/MatMul [MatMul]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense/Relu:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_1/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul [MatMul] inputs: [sequential/dense/Relu:0 -> (-1, 155)[FLOAT]], [sequential/dense_1/MatMul/ReadVariableOp:0 -> (155, 144)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_1/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense_1/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_1/MatMul for ONNX node: sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_1/MatMul:0 for ONNX tensor: sequential/dense_1/MatMul:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul [MatMul] outputs: [sequential/dense_1/MatMul:0 -> (-1, 144)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_1/BiasAdd [Add]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_1/MatMul:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_1/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/BiasAdd [Add] inputs: [sequential/dense_1/MatMul:0 -> (-1, 144)[FLOAT]], [sequential/dense_1/BiasAdd/ReadVariableOp:0 -> (144)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_1/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense_1/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_1/BiasAdd for ONNX node: sequential/dense_1/BiasAdd\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_1/BiasAdd:0 for ONNX tensor: sequential/dense_1/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/BiasAdd [Add] outputs: [sequential/dense_1/BiasAdd:0 -> (-1, 144)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_1/Relu [Relu]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_1/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/Relu [Relu] inputs: [sequential/dense_1/BiasAdd:0 -> (-1, 144)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_1/Relu for ONNX node: sequential/dense_1/Relu\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_1/Relu:0 for ONNX tensor: sequential/dense_1/Relu:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/Relu [Relu] outputs: [sequential/dense_1/Relu:0 -> (-1, 144)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_2/MatMul [MatMul]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_1/Relu:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_2/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul [MatMul] inputs: [sequential/dense_1/Relu:0 -> (-1, 144)[FLOAT]], [sequential/dense_2/MatMul/ReadVariableOp:0 -> (144, 63)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_2/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense_2/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_2/MatMul for ONNX node: sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_2/MatMul:0 for ONNX tensor: sequential/dense_2/MatMul:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul [MatMul] outputs: [sequential/dense_2/MatMul:0 -> (-1, 63)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_2/BiasAdd [Add]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_2/MatMul:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_2/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/BiasAdd [Add] inputs: [sequential/dense_2/MatMul:0 -> (-1, 63)[FLOAT]], [sequential/dense_2/BiasAdd/ReadVariableOp:0 -> (63)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_2/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense_2/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_2/BiasAdd for ONNX node: sequential/dense_2/BiasAdd\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_2/BiasAdd:0 for ONNX tensor: sequential/dense_2/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/BiasAdd [Add] outputs: [sequential/dense_2/BiasAdd:0 -> (-1, 63)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_2/Relu [Relu]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_2/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/Relu [Relu] inputs: [sequential/dense_2/BiasAdd:0 -> (-1, 63)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_2/Relu for ONNX node: sequential/dense_2/Relu\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_2/Relu:0 for ONNX tensor: sequential/dense_2/Relu:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/Relu [Relu] outputs: [sequential/dense_2/Relu:0 -> (-1, 63)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_3/MatMul [MatMul]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_2/Relu:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_3/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul [MatMul] inputs: [sequential/dense_2/Relu:0 -> (-1, 63)[FLOAT]], [sequential/dense_3/MatMul/ReadVariableOp:0 -> (63, 10)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_3/MatMul/ReadVariableOp:0 for ONNX node: sequential/dense_3/MatMul/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_3/MatMul for ONNX node: sequential/dense_3/MatMul\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_3/MatMul:0 for ONNX tensor: sequential/dense_3/MatMul:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul [MatMul] outputs: [sequential/dense_3/MatMul:0 -> (-1, 10)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_3/BiasAdd [Add]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_3/MatMul:0\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_3/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/BiasAdd [Add] inputs: [sequential/dense_3/MatMul:0 -> (-1, 10)[FLOAT]], [sequential/dense_3/BiasAdd/ReadVariableOp:0 -> (10)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_3/BiasAdd/ReadVariableOp:0 for ONNX node: sequential/dense_3/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_3/BiasAdd for ONNX node: sequential/dense_3/BiasAdd\n",
            "TRT - VERBOSE\n",
            "Registering tensor: sequential/dense_3/BiasAdd:0 for ONNX tensor: sequential/dense_3/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/BiasAdd [Add] outputs: [sequential/dense_3/BiasAdd:0 -> (-1, 10)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Parsing node: sequential/dense_3/Softmax [Softmax]\n",
            "TRT - VERBOSE\n",
            "Searching for input: sequential/dense_3/BiasAdd:0\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/Softmax [Softmax] inputs: [sequential/dense_3/BiasAdd:0 -> (-1, 10)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Registering layer: sequential/dense_3/Softmax for ONNX node: sequential/dense_3/Softmax\n",
            "TRT - VERBOSE\n",
            "Registering tensor: dense_3_0 for ONNX tensor: dense_3\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/Softmax [Softmax] outputs: [dense_3 -> (-1, 10)[FLOAT]], \n",
            "TRT - VERBOSE\n",
            "Marking dense_3_0 as output: dense_3\n",
            "Model parsing OK!\n",
            "Network Description\n",
            "Input 'input_1' with shape (-1, 28, 28, 1) and dtype DataType.FLOAT\n",
            "Output 'dense_3' with shape (-1, 10) and dtype DataType.FLOAT\n",
            "TRT - VERBOSE\n",
            "Applying generic optimizations to the graph for inference.\n",
            "TRT - VERBOSE\n",
            "Original: 26 layers\n",
            "TRT - VERBOSE\n",
            "After dead-layer removal: 26 layers\n",
            "TRT - VERBOSE\n",
            "Running: ConstShuffleFusion on sequential/dense/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "ConstShuffleFusion: Fusing sequential/dense/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 4) [Shuffle]\n",
            "TRT - VERBOSE\n",
            "Running: ConstShuffleFusion on sequential/dense_1/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "ConstShuffleFusion: Fusing sequential/dense_1/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 10) [Shuffle]\n",
            "TRT - VERBOSE\n",
            "Running: ConstShuffleFusion on sequential/dense_2/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "ConstShuffleFusion: Fusing sequential/dense_2/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 16) [Shuffle]\n",
            "TRT - VERBOSE\n",
            "Running: ConstShuffleFusion on sequential/dense_3/BiasAdd/ReadVariableOp:0\n",
            "TRT - VERBOSE\n",
            "ConstShuffleFusion: Fusing sequential/dense_3/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 22) [Shuffle]\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleErasure on (Unnamed Layer* 25) [Shuffle]\n",
            "TRT - VERBOSE\n",
            "Removing (Unnamed Layer* 25) [Shuffle]\n",
            "TRT - VERBOSE\n",
            "After Myelin optimization: 21 layers\n",
            "TRT - VERBOSE\n",
            "Running: MatMulToConvTransform on sequential/dense/MatMul\n",
            "TRT - VERBOSE\n",
            "Convert layer type of sequential/dense/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n",
            "TRT - VERBOSE\n",
            "Running: MatMulToConvTransform on sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "Convert layer type of sequential/dense_1/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n",
            "TRT - VERBOSE\n",
            "Running: MatMulToConvTransform on sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "Convert layer type of sequential/dense_2/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n",
            "TRT - VERBOSE\n",
            "Running: MatMulToConvTransform on sequential/dense_3/MatMul\n",
            "TRT - VERBOSE\n",
            "Convert layer type of sequential/dense_3/MatMul from MATRIX_MULTIPLY to CONVOLUTION\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleShuffleFusion on sequential/flatten/Reshape\n",
            "TRT - VERBOSE\n",
            "ShuffleShuffleFusion: Fusing sequential/flatten/Reshape with reshape_before_sequential/dense/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ConvReshapeBiasAddFusion on sequential/dense/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ConvReshapeBiasAddFusion on sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ConvReshapeBiasAddFusion on sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ConvReshapeBiasAddFusion on sequential/dense_3/MatMul\n",
            "TRT - VERBOSE\n",
            "Applying ScaleNodes fusions.\n",
            "TRT - VERBOSE\n",
            "After scale fusion: 16 layers\n",
            "TRT - VERBOSE\n",
            "Running: SqueezePushDownFork on reshape_after_sequential/dense/MatMul\n",
            "TRT - VERBOSE\n",
            "-----------SqueezePushDown kSQUEEZE_FORK case: sequential/dense/MatMul --> reshape_after_sequential/dense/MatMul --> sequential/dense/Relu\n",
            "TRT - VERBOSE\n",
            "Running: SqueezePushDownFork on reshape_after_sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "-----------SqueezePushDown kSQUEEZE_FORK case: sequential/dense_1/MatMul --> reshape_after_sequential/dense_1/MatMul --> sequential/dense_1/Relu\n",
            "TRT - VERBOSE\n",
            "Running: SqueezePushDownFork on reshape_after_sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "-----------SqueezePushDown kSQUEEZE_FORK case: sequential/dense_2/MatMul --> reshape_after_sequential/dense_2/MatMul --> sequential/dense_2/Relu\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleShuffleFusion on squeeze_after_sequential/dense/Relu\n",
            "TRT - VERBOSE\n",
            "ShuffleShuffleFusion: Fusing squeeze_after_sequential/dense/Relu with reshape_before_sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleShuffleFusion on squeeze_after_sequential/dense_1/Relu\n",
            "TRT - VERBOSE\n",
            "ShuffleShuffleFusion: Fusing squeeze_after_sequential/dense_1/Relu with reshape_before_sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleShuffleFusion on squeeze_after_sequential/dense_2/Relu\n",
            "TRT - VERBOSE\n",
            "ShuffleShuffleFusion: Fusing squeeze_after_sequential/dense_2/Relu with reshape_before_sequential/dense_3/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ConvReluFusion on sequential/dense/MatMul\n",
            "TRT - VERBOSE\n",
            "ConvReluFusion: Fusing sequential/dense/MatMul with sequential/dense/Relu\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleErasure on squeeze_after_sequential/dense/Relu + reshape_before_sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "Removing squeeze_after_sequential/dense/Relu + reshape_before_sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ConvReluFusion on sequential/dense_1/MatMul\n",
            "TRT - VERBOSE\n",
            "ConvReluFusion: Fusing sequential/dense_1/MatMul with sequential/dense_1/Relu\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleErasure on squeeze_after_sequential/dense_1/Relu + reshape_before_sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "Removing squeeze_after_sequential/dense_1/Relu + reshape_before_sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "Running: ConvReluFusion on sequential/dense_2/MatMul\n",
            "TRT - VERBOSE\n",
            "ConvReluFusion: Fusing sequential/dense_2/MatMul with sequential/dense_2/Relu\n",
            "TRT - VERBOSE\n",
            "Running: ShuffleErasure on squeeze_after_sequential/dense_2/Relu + reshape_before_sequential/dense_3/MatMul\n",
            "TRT - VERBOSE\n",
            "Removing squeeze_after_sequential/dense_2/Relu + reshape_before_sequential/dense_3/MatMul\n",
            "TRT - VERBOSE\n",
            "After dupe layer removal: 7 layers\n",
            "TRT - VERBOSE\n",
            "After final dead-layer removal: 7 layers\n",
            "TRT - VERBOSE\n",
            "After tensor merging: 7 layers\n",
            "TRT - VERBOSE\n",
            "After vertical fusions: 7 layers\n",
            "TRT - VERBOSE\n",
            "After dupe layer removal: 7 layers\n",
            "TRT - VERBOSE\n",
            "After final dead-layer removal: 7 layers\n",
            "TRT - VERBOSE\n",
            "After tensor merging: 7 layers\n",
            "TRT - VERBOSE\n",
            "After slice removal: 7 layers\n",
            "TRT - VERBOSE\n",
            "After concat removal: 7 layers\n",
            "TRT - VERBOSE\n",
            "Trying to split Reshape and strided tensor\n",
            "TRT - VERBOSE\n",
            "Graph construction and optimization completed in 0.127622 seconds.\n",
            "TRT - VERBOSE\n",
            "Using cublasLt as a tactic source\n",
            "TRT - INFO\n",
            "[MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 0, GPU 1289 (MiB)\n",
            "TRT - VERBOSE\n",
            "Using cuDNN as a tactic source\n",
            "TRT - INFO\n",
            "[MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 0, GPU 1297 (MiB)\n",
            "TRT - WARNING\n",
            "TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n",
            "TRT - INFO\n",
            "Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "TRT - VERBOSE\n",
            "Constructing optimization profile number 0 [1/1].\n",
            "TRT - VERBOSE\n",
            "Reserving memory for host IO tensors. Host: 0 bytes\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,28,1,1) -> Float(784,1,28,28) ***************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:226: DeprecationWarning: Use build_serialized_network instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(input_1 -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00730644\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0286782\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.116945\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00730644\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,28,1,1) -> Float(28,28:32,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(input_1 -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00796343\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0251817\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00727026\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00727026\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,28,1,1) -> Half(784,28,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(input_1 -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00611665\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0141027\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00644513\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00611665\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,28,1,1) -> Half(392,28:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(input_1 -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00632231\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0125819\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00598171\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00598171\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,28,1,1) -> Half(112,1:8,4,4) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(input_1 -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00628484\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.012171\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00645313\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00628484\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,1,1) -> Float(784,1,784,784) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0063195\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0130761\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.006504\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0063195\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,1,1) -> Half(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00626726\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0137271\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0063352\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00626726\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,1,1) -> Half(392,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00626924\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0137131\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00646154\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00626924\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,1,1) -> Half(98,1:8,98,98) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00642838\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0131984\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00641489\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00641489\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,784,784) -> Float(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00660664\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0128496\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00616456\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00616456\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,784,784) -> Half(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00642133\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0122568\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0063356\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0063356\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,784,784) -> Half(392,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00610851\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0132082\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00631743\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00610851\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(784,1,784,784) -> Half(98,1:8,98,98) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0072\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0160122\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.019696\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0072\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(25,1:32,1,1) -> Float(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00674496\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0234169\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00617837\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00617837\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(25,1:32,1,1) -> Float(784,1,784,784) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0061837\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0236871\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00641912\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0061837\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(25,1:32,1,1) -> Half(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00634848\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0128821\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00662065\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00634848\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(25,1:32,1,1) -> Half(392,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00675648\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0141227\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00634244\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00634244\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(25,1:32,1,1) -> Half(98,1:8,98,98) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00664471\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.012732\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00683494\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00664471\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(784,1,1,1) -> Float(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00641288\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0139693\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00618035\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00618035\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(784,1,1,1) -> Float(784,1,784,784) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00706044\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0146922\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00708133\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00706044\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(784,1,1,1) -> Half(392,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00791219\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0164688\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00711172\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00711172\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(784,1,1,1) -> Half(98,1:8,98,98) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00625185\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0165664\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.006624\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00625185\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(392,1:2,1,1) -> Float(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0244175\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0294267\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0211067\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0211067\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(392,1:2,1,1) -> Float(784,1,784,784) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00712034\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0140124\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00737299\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00712034\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(392,1:2,1,1) -> Half(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00796089\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0142338\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00613547\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00613547\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(392,1:2,1,1) -> Half(98,1:8,98,98) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00740452\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0142173\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00701044\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00701044\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(98,1:8,98,98) -> Float(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00717685\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0121985\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00540507\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00540507\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(98,1:8,98,98) -> Float(784,1,784,784) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00607845\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0121939\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00608446\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00607845\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(98,1:8,98,98) -> Half(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00632413\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0119897\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00610762\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00610762\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(98,1:8,98,98) -> Half(392,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00703289\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0140702\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00644903\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00644903\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,1,1) -> Float(155,1,155,155) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00676501\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0231737\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0214707\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00676501\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,1,1) -> Half(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0243787\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0164927\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.115031\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003ea Time: 0.0164927\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,1,1) -> Half(78,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00684691\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.016034\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00619358\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00619358\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,1,1) -> Half(20,1:8,20,20) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00800381\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0177185\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00735281\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00735281\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,155,155) -> Float(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00611029\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0235861\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00803225\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00611029\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,155,155) -> Half(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0064482\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0162941\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00655373\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0064482\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,155,155) -> Half(78,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00649169\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0117587\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.007032\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00649169\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(155,1,155,155) -> Half(20,1:8,20,20) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00619793\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.012248\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00621412\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00619793\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(155,1,1,1) -> Float(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00552306\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0123982\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00551939\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00551939\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(155,1,1,1) -> Float(155,1,155,155) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00589118\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0116866\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0060421\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00589118\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(155,1,1,1) -> Half(78,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0225806\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0293787\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0199523\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0199523\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(155,1,1,1) -> Half(20,1:8,20,20) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0212387\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.02952\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0206249\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0206249\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(78,1:2,1,1) -> Float(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.021652\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0294676\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0214687\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0214687\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(78,1:2,1,1) -> Float(155,1,155,155) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0222813\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0307491\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0218287\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0218287\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(78,1:2,1,1) -> Half(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0216147\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0297671\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0225941\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0216147\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(78,1:2,1,1) -> Half(20,1:8,20,20) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0219133\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0294453\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.021112\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.021112\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(20,1:8,20,20) -> Float(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0229127\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0292311\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0204944\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0204944\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(20,1:8,20,20) -> Float(155,1,155,155) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0210907\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0274609\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0204543\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0204543\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(20,1:8,20,20) -> Half(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0257616\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0276587\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0204273\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0204273\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(20,1:8,20,20) -> Half(78,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0231787\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0282996\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0218053\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0218053\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,1,1) -> Float(144,1,144,144) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0217793\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0290658\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0215813\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0215813\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,1,1) -> Half(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.02239\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0307452\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0203495\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0203495\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,1,1) -> Half(72,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0223936\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0305513\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.021482\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.021482\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,1,1) -> Half(18,1:8,18,18) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0224284\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0308713\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0215673\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0215673\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,144,144) -> Float(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.024192\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0290471\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0218453\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0218453\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,144,144) -> Half(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0220847\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0293129\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0071882\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0071882\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,144,144) -> Half(72,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00695333\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0183955\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00770594\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00695333\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(144,1,144,144) -> Half(18,1:8,18,18) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00704778\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0172432\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00742139\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00704778\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(144,1,1,1) -> Float(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00654348\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0118367\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00898462\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00654348\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(144,1,1,1) -> Float(144,1,144,144) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00963505\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0147933\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00789383\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00789383\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(144,1,1,1) -> Half(72,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00746829\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0154225\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0072691\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0072691\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(144,1,1,1) -> Half(18,1:8,18,18) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.005696\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0117738\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.005456\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.005456\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(72,1:2,1,1) -> Float(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00599067\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0122514\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00567358\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00567358\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(72,1:2,1,1) -> Float(144,1,144,144) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00614652\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.011879\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00606681\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00606681\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(72,1:2,1,1) -> Half(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00582253\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0116947\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00567521\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00567521\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(72,1:2,1,1) -> Half(18,1:8,18,18) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00974116\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0122537\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00546745\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00546745\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(18,1:8,18,18) -> Float(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00589661\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0112768\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00555698\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00555698\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(18,1:8,18,18) -> Float(144,1,144,144) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0060019\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0142676\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.010143\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0060019\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(18,1:8,18,18) -> Half(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00581425\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0121204\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0057714\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0057714\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(18,1:8,18,18) -> Half(72,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_1/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00745363\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0130351\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00573686\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00573686\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,1,1) -> Float(63,1,63,63) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00594732\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0232057\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00587453\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00587453\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,1,1) -> Half(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00570847\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0121608\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00597448\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00570847\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,1,1) -> Half(32,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0061409\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0122042\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00567503\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00567503\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,1,1) -> Half(8,1:8,8,8) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00624968\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0120141\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0057365\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0057365\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,63,63) -> Float(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00597752\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.026976\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.022056\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00597752\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,63,63) -> Half(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0214253\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0292311\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0214667\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0214253\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,63,63) -> Half(32,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0216947\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0298587\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.021586\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.021586\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(63,1,63,63) -> Half(8,1:8,8,8) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0217127\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0299093\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0230279\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0217127\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(63,1,1,1) -> Float(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00612577\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0244983\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00671744\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00612577\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(63,1,1,1) -> Float(63,1,63,63) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00851787\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0136657\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00907647\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00851787\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(63,1,1,1) -> Half(32,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00805689\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0167599\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00656185\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00656185\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(63,1,1,1) -> Half(8,1:8,8,8) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00648431\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0140196\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00766861\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00648431\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(32,1:2,1,1) -> Float(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00769527\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0141258\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00736742\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00736742\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(32,1:2,1,1) -> Float(63,1,63,63) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00644185\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0137519\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00795378\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00644185\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(32,1:2,1,1) -> Half(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00622775\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.014364\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00637706\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00622775\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(32,1:2,1,1) -> Half(8,1:8,8,8) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00760699\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0183461\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0116768\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00760699\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(8,1:8,8,8) -> Float(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00808432\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0145878\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00673067\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00673067\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(8,1:8,8,8) -> Float(63,1,63,63) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00729827\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0168603\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.007952\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00729827\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(8,1:8,8,8) -> Half(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00632312\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0131611\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00596914\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00596914\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(8,1:8,8,8) -> Half(32,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_2/Relu_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00702778\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0130462\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00712778\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00702778\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(10,1,1,1) -> Half(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0354052\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0190987\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00733194\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00733194\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(10,1,10,10) -> Float(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00830095\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.023859\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00762085\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00762085\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(10,1,10,10) -> Half(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00734207\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0135113\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00650585\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00650585\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(10,1,1,1) -> Float(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0230777\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0297742\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0233671\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0230777\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(5,1:2,1,1) -> Float(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0231076\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0333702\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0250438\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.0231076\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(5,1:2,1,1) -> Half(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0225586\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0296107\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0215567\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0215567\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(2,1:8,2,2) -> Float(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.0223339\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0286222\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0205484\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0205484\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(2,1:8,2,2) -> Half(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/MatMul_out_tensor -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00715665\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0133636\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00656146\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00656146\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Float(10,1) -> Half(10,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/BiasAdd:0 -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00653887\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0152645\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00646769\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00646769\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(10,1) -> Float(10,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(sequential/dense_3/BiasAdd:0 -> <out>) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00675029\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0141702\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0068763\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e8 Time: 0.00675029\n",
            "TRT - VERBOSE\n",
            "=============== Computing reformatting costs\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning Reformat: Half(10,1) -> Float(10,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: Optimizer Reformat(<in> -> dense_3) (Reformat)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e8 Time: 0.00661793\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0168827\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.00602076\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.00602076\n",
            "TRT - VERBOSE\n",
            "=============== Computing costs for \n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(784,28,1,1) -> Float(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.010783\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0556404\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.010783\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(784,1,28,28) -> Float(784,1,784,784) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0212893\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0452027\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0212893\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(28,28:32,1,1) -> Float(25,1:32,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0221107\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.056224\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0221107\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(784,28,1,1) -> Half(784,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0223829\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0417467\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0223829\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(392,28:2,1,1) -> Half(392,1:2,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0210927\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0455013\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0210927\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(112,1:8,4,4) -> Half(98,1:8,98,98) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0217307\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0425373\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0217307\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "=============== Computing costs for \n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(784,1,1,1) -> Float(155,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.115929\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.11605\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.194832\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 2.27123\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.293531\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.1159\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000039 Time: 0.0187289\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.195248\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 2.27094\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.293781\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000039 Time: 0.0187289\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0285609\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0452717\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0285609\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x128_relu_interior_nn_v1 Tactic: 0x18597bd4a7d0164d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x18597bd4a7d0164d Time: 0.367093\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x128_relu_medium_nn_v1 Tactic: 0x195431d38ba5af88\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x195431d38ba5af88 Time: 0.370443\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x25eed4cfa195d49d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x25eed4cfa195d49d Time: 0.233877\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x128_relu_small_nn_v1 Tactic: 0x365602d0613d4c36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x365602d0613d4c36 Time: 0.365909\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x5193693bc0732c65\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5193693bc0732c65 Time: 0.140487\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x64_relu_small_nn_v1 Tactic: 0x5e7d1125e7896624\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5e7d1125e7896624 Time: 0.221691\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x64_relu_interior_nn_v1 Tactic: 0x7e29bdfccd92c42c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e29bdfccd92c42c Time: 0.216848\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x64_relu_medium_nn_v1 Tactic: 0x90238daf8750ddb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x90238daf8750ddb0 Time: 0.234219\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa0dcf7c2b333d150\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa0dcf7c2b333d150 Time: 0.233472\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa3cd285aae791bdd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa3cd285aae791bdd Time: 0.138372\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaa0953b1a73b0b9b Time: 0.0262482\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x32_relu_medium_nn_v1 Tactic: 0xc2a5fc6b5e7cef5e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc2a5fc6b5e7cef5e Time: 0.177851\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_scudnn_128x32_relu_small_nn_v1 Tactic: 0xc939b7b0a4d5a05f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc939b7b0a4d5a05f Time: 0.239045\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.0262482\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0x0000000000000039\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(784,1,784,784) -> Float(155,1,155,155) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x704db0897ce9340d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x704db0897ce9340d Time: 0.113067\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa79cf41de521f476\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa79cf41de521f476 Time: 0.199947\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xded29d328f8f7228\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xded29d328f8f7228 Time: 0.116992\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage1_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xe957dcfcec24ec5d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe957dcfcec24ec5d Time: 0.199355\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfbba95cf52891795\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbba95cf52891795 Time: 0.199515\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x704db0897ce9340d Time: 0.113067\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x704db0897ce9340d\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(784,1,1,1) -> Half(155,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.319952\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.122805\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.3872\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 2.26291\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.28648\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.319829\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.387083\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 2.26475\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.287424\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000001 Time: 0.122805\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0240498\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0309615\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0301191\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000003 Time: 0.0308179\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.211595\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.200976\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000006 Time: 0.0323239\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000007 Time: 0.037133\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0240498\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(392,1:2,1,1) -> Half(155,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9306c3a1111e5472 Time: 0.0209487\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x9306c3a1111e5472 Time: 0.0209487\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(392,1:2,1,1) -> Half(78,1:2,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x16eafdbc5869b184\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x16eafdbc5869b184 Time: 0.124683\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x21904dd9d0cd407e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21904dd9d0cd407e Time: 0.123762\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x3bee4a098b4f8914\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3bee4a098b4f8914 Time: 0.118414\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x446c8c788145836a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x446c8c788145836a Time: 0.125305\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x73163c1d09e17290\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x73163c1d09e17290 Time: 0.12378\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x7498280d2c59e4aa\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7498280d2c59e4aa Time: 0.116686\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0x87e5c2a636a0d1f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x87e5c2a636a0d1f8 Time: 0.190464\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0x97afba3735828021\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x97afba3735828021 Time: 0.112188\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0x9ce6ebc390e62b01\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9ce6ebc390e62b01 Time: 0.112107\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xacaaec9cc8134f6f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xacaaec9cc8134f6f Time: 0.119812\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0xb09f72c3be042002\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb09f72c3be042002 Time: 0.190613\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0xc72182f0fce13bb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc72182f0fce13bb0 Time: 0.111858\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0xcc68d30459859090\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xcc68d30459859090 Time: 0.110893\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xccca8c966967f8f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xccca8c966967f8f8 Time: 0.1912\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdb5acaea7b0746d5\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdb5acaea7b0746d5 Time: 0.18976\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdcd3fec139dd130a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdcd3fec139dd130a Time: 0.189675\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xe3dc8e986f0522d1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe3dc8e986f0522d1 Time: 0.113938\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xe4aed86f94a0620c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe4aed86f94a0620c Time: 0.191349\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xcc68d30459859090 Time: 0.110893\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcc68d30459859090\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(98,1:8,98,98) -> Float(155,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(98,1:8,98,98) -> Half(20,1:8,20,20) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense/MatMul + sequential/dense/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense/MatMul + sequential/dense/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x0129597ad9bbff14\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0129597ad9bbff14 Time: 0.0305222\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x017a89ce2d82b850\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x017a89ce2d82b850 Time: 0.019941\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x105f56cf03ee5549\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x105f56cf03ee5549 Time: 0.0654382\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x1d38ef2fc1ec5804\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1d38ef2fc1ec5804 Time: 0.10632\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x1dcf9babce3d9b3b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1dcf9babce3d9b3b Time: 0.0662773\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x21739cdb4c6113ed\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21739cdb4c6113ed Time: 0.112078\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r1s1 Tactic: 0x22dbd03ae6f5a915\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x22dbd03ae6f5a915 Time: 0.0659502\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x249110624ee04937\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x249110624ee04937 Time: 0.0421893\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x255200b1b31c45cd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x255200b1b31c45cd Time: 0.194651\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x26d4c2773a9a6efc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x26d4c2773a9a6efc Time: 0.105472\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x2a3615ad33745f0b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2a3615ad33745f0b Time: 0.0635893\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x2ae5fedb80fbd388\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2ae5fedb80fbd388 Time: 0.105064\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x2c6739dc8daca583\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2c6739dc8daca583 Time: 0.0656711\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x34192289eb1f5427\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x34192289eb1f5427 Time: 0.110627\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x3693535b668f43cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3693535b668f43cb Time: 0.0345792\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x399448b5af8ca81a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x399448b5af8ca81a Time: 0.042484\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x3f3840edab5c9d44\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3f3840edab5c9d44 Time: 0.0680085\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x41e8a431d0137286\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x41e8a431d0137286 Time: 0.0312785\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x4c17dc9d992e6a1d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4c17dc9d992e6a1d Time: 0.0580978\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x4ea23ec81add686f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4ea23ec81add686f Time: 0.110605\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x51e3312bfd062f36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x51e3312bfd062f36 Time: 0.0617476\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x523aca1fca7ef548\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x523aca1fca7ef548 Time: 0.192325\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x53422c5d4478d3d7\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x53422c5d4478d3d7 Time: 0.059152\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x5cb7625ea24db701\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5cb7625ea24db701 Time: 0.112395\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x62a22cfa1199e58e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x62a22cfa1199e58e Time: 0.0270892\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x63566dea68ccc247\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x63566dea68ccc247 Time: 0.10444\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x6d1428d5257a3dc9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x6d1428d5257a3dc9 Time: 0.110677\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x72f623a1c870d417\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x72f623a1c870d417 Time: 0.110944\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7585679fc3cc2536\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7585679fc3cc2536 Time: 0.109339\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x77a26840a2ace0b3\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77a26840a2ace0b3 Time: 0.109637\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x77ef8bb029e1d4e0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77ef8bb029e1d4e0 Time: 0.109797\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7ca057c91d677737\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7ca057c91d677737 Time: 0.042468\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x7e665af4f37d210b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e665af4f37d210b Time: 0.0592284\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x81a7be09ad63581a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x81a7be09ad63581a Time: 0.0253029\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x833510adbbf772c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x833510adbbf772c4 Time: 0.0743083\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x83b35618df65874c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83b35618df65874c Time: 0.0612213\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x83c3f470a0ec89f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83c3f470a0ec89f9 Time: 0.107013\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8480e919254b99f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8480e919254b99f8 Time: 0.111399\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_t1r1s1 Tactic: 0x8639a0d23c8a1708\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8639a0d23c8a1708 Time: 0.107669\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x86937c170a111d1f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x86937c170a111d1f Time: 0.109645\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x89c2d153627e52ba\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x89c2d153627e52ba Time: 0.0353621\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8a37d1d6d41033e6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8a37d1d6d41033e6 Time: 0.195195\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x8b8a7a5cef8d932b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8b8a7a5cef8d932b Time: 0.191221\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x911cdd8d308bed5c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x911cdd8d308bed5c Time: 0.0396776\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x93125939e1fba374\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x93125939e1fba374 Time: 0.194725\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x9774d044044b6a7d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9774d044044b6a7d Time: 0.0399799\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xa8f10051cbdaaa96\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa8f10051cbdaaa96 Time: 0.0677163\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xaf407014f2c7f1cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaf407014f2c7f1cb Time: 0.0656924\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb26ad7a19a3195cc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb26ad7a19a3195cc Time: 0.0578116\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb3989f8802666c8a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb3989f8802666c8a Time: 0.068928\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb5342eac22cbe342\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5342eac22cbe342 Time: 0.194091\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb5fdd9dd73a52c67\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5fdd9dd73a52c67 Time: 0.0396551\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xb8eb6a106c53cff6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb8eb6a106c53cff6 Time: 0.0663929\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xba86f9c788dfb2dc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xba86f9c788dfb2dc Time: 0.066608\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xc110e19c9f5aa36e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc110e19c9f5aa36e Time: 0.191403\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc399fdbffdc34032\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc399fdbffdc34032 Time: 0.0704811\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc6f99965cbd03fdf\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc6f99965cbd03fdf Time: 0.109853\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd313af1c92b241c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd313af1c92b241c4 Time: 0.103192\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd47a5fce3824e4a4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd47a5fce3824e4a4 Time: 0.0648533\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r1s1 Tactic: 0xd8c128ae16cb4132\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd8c128ae16cb4132 Time: 0.0200558\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0xdadc728a0ae041d9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdadc728a0ae041d9 Time: 0.0405677\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xdbe57b4edf7481d8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdbe57b4edf7481d8 Time: 0.0649102\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xdc1c841ef1cd3e8e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc1c841ef1cd3e8e Time: 0.113095\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xdc559b3944b0cdf8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc559b3944b0cdf8 Time: 0.0431747\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xde62c240f3a7d930\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xde62c240f3a7d930 Time: 0.110157\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe281d0b88acb38b8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe281d0b88acb38b8 Time: 0.107283\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe2866ff18c9049f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe2866ff18c9049f9 Time: 0.104941\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xe67db95e0c20b618\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe67db95e0c20b618 Time: 0.0276094\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xef1e5139c624a44f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xef1e5139c624a44f Time: 0.111442\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_t1r1s1 Tactic: 0xf883bd61103a5c32\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xf883bd61103a5c32 Time: 0.0279973\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xfbff59172cce263c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbff59172cce263c Time: 0.0605422\n",
            "TRT - VERBOSE\n",
            "sequential/dense/MatMul + sequential/dense/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xfcd06da0f3c31fd1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfcd06da0f3c31fd1 Time: 0.0583609\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x017a89ce2d82b850 Time: 0.019941\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x017a89ce2d82b850\n",
            "TRT - VERBOSE\n",
            "=============== Computing costs for \n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(155,1,1,1) -> Float(144,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0319273\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0319796\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0815936\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.452459\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.0773739\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.0320407\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000039 Time: 0.0151295\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.081536\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 0.454048\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.0761707\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000039 Time: 0.0151295\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0306599\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0310545\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0306599\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x128_relu_interior_nn_v1 Tactic: 0x18597bd4a7d0164d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x18597bd4a7d0164d Time: 0.0778347\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x128_relu_medium_nn_v1 Tactic: 0x195431d38ba5af88\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x195431d38ba5af88 Time: 0.0788843\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x25eed4cfa195d49d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x25eed4cfa195d49d Time: 0.0550629\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x128_relu_small_nn_v1 Tactic: 0x365602d0613d4c36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x365602d0613d4c36 Time: 0.0780288\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x5193693bc0732c65\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5193693bc0732c65 Time: 0.0343797\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x64_relu_small_nn_v1 Tactic: 0x5e7d1125e7896624\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5e7d1125e7896624 Time: 0.051584\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x64_relu_interior_nn_v1 Tactic: 0x7e29bdfccd92c42c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e29bdfccd92c42c Time: 0.0501669\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x64_relu_medium_nn_v1 Tactic: 0x90238daf8750ddb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x90238daf8750ddb0 Time: 0.05392\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa0dcf7c2b333d150\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa0dcf7c2b333d150 Time: 0.0591289\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa3cd285aae791bdd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa3cd285aae791bdd Time: 0.0348608\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaa0953b1a73b0b9b Time: 0.0258363\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x32_relu_medium_nn_v1 Tactic: 0xc2a5fc6b5e7cef5e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc2a5fc6b5e7cef5e Time: 0.043312\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x32_relu_small_nn_v1 Tactic: 0xc939b7b0a4d5a05f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc939b7b0a4d5a05f Time: 0.0558542\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.0258363\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0x0000000000000039\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(155,1,155,155) -> Float(144,1,144,144) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: 0x0bf55a7b77a6ff98\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0bf55a7b77a6ff98 Time: 0.0753365\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 0x50ca8db54378cbac\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x50ca8db54378cbac Time: 0.0749141\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x704db0897ce9340d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x704db0897ce9340d Time: 0.0296018\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa79cf41de521f476\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa79cf41de521f476 Time: 0.0513097\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0xb90177ab6d659acd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb90177ab6d659acd Time: 0.0746581\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xded29d328f8f7228\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xded29d328f8f7228 Time: 0.0295316\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage1_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xe957dcfcec24ec5d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe957dcfcec24ec5d Time: 0.0503589\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfbba95cf52891795\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbba95cf52891795 Time: 0.0505006\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xded29d328f8f7228 Time: 0.0295316\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xded29d328f8f7228\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(155,1,1,1) -> Half(144,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0726336\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0848\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.115399\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.448512\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.128149\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.0688299\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.115399\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 0.45056\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.114994\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000038 Time: 0.0688299\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0308625\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0306628\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0397084\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000003 Time: 0.029888\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.0506331\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.0483474\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000006 Time: 0.0329532\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000007 Time: 0.0316703\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000003 Time: 0.029888\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(78,1:2,1,1) -> Half(144,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9306c3a1111e5472 Time: 0.0266617\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x9306c3a1111e5472 Time: 0.0266617\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(78,1:2,1,1) -> Half(72,1:2,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x16eafdbc5869b184\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x16eafdbc5869b184 Time: 0.0320979\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x21904dd9d0cd407e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21904dd9d0cd407e Time: 0.0320698\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x3bee4a098b4f8914\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3bee4a098b4f8914 Time: 0.0308722\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x446c8c788145836a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x446c8c788145836a Time: 0.0324596\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x73163c1d09e17290\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x73163c1d09e17290 Time: 0.0321387\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x7498280d2c59e4aa\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7498280d2c59e4aa Time: 0.0324461\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0x87e5c2a636a0d1f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x87e5c2a636a0d1f8 Time: 0.0440093\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0x97afba3735828021\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x97afba3735828021 Time: 0.0298844\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0x9ce6ebc390e62b01\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9ce6ebc390e62b01 Time: 0.0300124\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xacaaec9cc8134f6f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xacaaec9cc8134f6f Time: 0.0310904\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0xb09f72c3be042002\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb09f72c3be042002 Time: 0.044084\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0xc72182f0fce13bb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc72182f0fce13bb0 Time: 0.0298347\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0xcc68d30459859090\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xcc68d30459859090 Time: 0.0297422\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xccca8c966967f8f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xccca8c966967f8f8 Time: 0.0442653\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdb5acaea7b0746d5\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdb5acaea7b0746d5 Time: 0.0436067\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdcd3fec139dd130a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdcd3fec139dd130a Time: 0.0436293\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xe3dc8e986f0522d1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe3dc8e986f0522d1 Time: 0.030152\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xe4aed86f94a0620c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe4aed86f94a0620c Time: 0.044192\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xcc68d30459859090 Time: 0.0297422\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcc68d30459859090\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(20,1:8,20,20) -> Float(144,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(20,1:8,20,20) -> Half(18,1:8,18,18) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_1/MatMul + sequential/dense_1/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_1/MatMul + sequential/dense_1/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x0129597ad9bbff14\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0129597ad9bbff14 Time: 0.0124911\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x017a89ce2d82b850\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x017a89ce2d82b850 Time: 0.0101754\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x105f56cf03ee5549\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x105f56cf03ee5549 Time: 0.0240739\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x1d38ef2fc1ec5804\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1d38ef2fc1ec5804 Time: 0.0279404\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x1dcf9babce3d9b3b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1dcf9babce3d9b3b Time: 0.021558\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x21739cdb4c6113ed\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21739cdb4c6113ed Time: 0.0338315\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r1s1 Tactic: 0x22dbd03ae6f5a915\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x22dbd03ae6f5a915 Time: 0.0238255\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x249110624ee04937\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x249110624ee04937 Time: 0.0157532\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x255200b1b31c45cd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x255200b1b31c45cd Time: 0.0464547\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x26d4c2773a9a6efc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x26d4c2773a9a6efc Time: 0.0303321\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x2a3615ad33745f0b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2a3615ad33745f0b Time: 0.0224235\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x2ae5fedb80fbd388\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2ae5fedb80fbd388 Time: 0.0299458\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x2c6739dc8daca583\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2c6739dc8daca583 Time: 0.0250606\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x34192289eb1f5427\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x34192289eb1f5427 Time: 0.0283867\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x3693535b668f43cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3693535b668f43cb Time: 0.0159578\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x399448b5af8ca81a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x399448b5af8ca81a Time: 0.0162027\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x3f3840edab5c9d44\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3f3840edab5c9d44 Time: 0.0227373\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x41e8a431d0137286\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x41e8a431d0137286 Time: 0.0243429\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x4c17dc9d992e6a1d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4c17dc9d992e6a1d Time: 0.0189962\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x4ea23ec81add686f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4ea23ec81add686f Time: 0.0281378\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x51e3312bfd062f36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x51e3312bfd062f36 Time: 0.0198193\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x523aca1fca7ef548\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x523aca1fca7ef548 Time: 0.0435\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x53422c5d4478d3d7\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x53422c5d4478d3d7 Time: 0.0192527\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x5cb7625ea24db701\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5cb7625ea24db701 Time: 0.0332616\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x62a22cfa1199e58e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x62a22cfa1199e58e Time: 0.0168965\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x63566dea68ccc247\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x63566dea68ccc247 Time: 0.0280738\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x6d1428d5257a3dc9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x6d1428d5257a3dc9 Time: 0.0326177\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x72f623a1c870d417\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x72f623a1c870d417 Time: 0.0283582\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7585679fc3cc2536\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7585679fc3cc2536 Time: 0.032129\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x77a26840a2ace0b3\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77a26840a2ace0b3 Time: 0.0323927\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x77ef8bb029e1d4e0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77ef8bb029e1d4e0 Time: 0.0339872\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7ca057c91d677737\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7ca057c91d677737 Time: 0.0162418\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x7e665af4f37d210b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e665af4f37d210b Time: 0.0188575\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x81a7be09ad63581a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x81a7be09ad63581a Time: 0.0241691\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x833510adbbf772c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x833510adbbf772c4 Time: 0.0231452\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x83b35618df65874c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83b35618df65874c Time: 0.019501\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x83c3f470a0ec89f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83c3f470a0ec89f9 Time: 0.0317052\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8480e919254b99f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8480e919254b99f8 Time: 0.0354347\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_t1r1s1 Tactic: 0x8639a0d23c8a1708\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8639a0d23c8a1708 Time: 0.0318002\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x86937c170a111d1f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x86937c170a111d1f Time: 0.0480076\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x89c2d153627e52ba\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x89c2d153627e52ba Time: 0.0143378\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8a37d1d6d41033e6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8a37d1d6d41033e6 Time: 0.04664\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x8b8a7a5cef8d932b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8b8a7a5cef8d932b Time: 0.0431707\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x911cdd8d308bed5c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x911cdd8d308bed5c Time: 0.0149843\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x93125939e1fba374\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x93125939e1fba374 Time: 0.0466973\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x9774d044044b6a7d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9774d044044b6a7d Time: 0.0179582\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xa8f10051cbdaaa96\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa8f10051cbdaaa96 Time: 0.0249973\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xaf407014f2c7f1cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaf407014f2c7f1cb Time: 0.0252861\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb26ad7a19a3195cc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb26ad7a19a3195cc Time: 0.0196201\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb3989f8802666c8a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb3989f8802666c8a Time: 0.0260209\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb5342eac22cbe342\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5342eac22cbe342 Time: 0.0460693\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb5fdd9dd73a52c67\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5fdd9dd73a52c67 Time: 0.015966\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xb8eb6a106c53cff6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb8eb6a106c53cff6 Time: 0.0236594\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xba86f9c788dfb2dc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xba86f9c788dfb2dc Time: 0.0243741\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xc110e19c9f5aa36e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc110e19c9f5aa36e Time: 0.043236\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc399fdbffdc34032\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc399fdbffdc34032 Time: 0.027232\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc6f99965cbd03fdf\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc6f99965cbd03fdf Time: 0.0324965\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd313af1c92b241c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd313af1c92b241c4 Time: 0.0277563\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd47a5fce3824e4a4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd47a5fce3824e4a4 Time: 0.023035\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r1s1 Tactic: 0xd8c128ae16cb4132\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd8c128ae16cb4132 Time: 0.0197636\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0xdadc728a0ae041d9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdadc728a0ae041d9 Time: 0.0168736\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xdbe57b4edf7481d8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdbe57b4edf7481d8 Time: 0.0225294\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xdc1c841ef1cd3e8e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc1c841ef1cd3e8e Time: 0.0341845\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xdc559b3944b0cdf8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc559b3944b0cdf8 Time: 0.0168517\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xde62c240f3a7d930\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xde62c240f3a7d930 Time: 0.0324684\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe281d0b88acb38b8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe281d0b88acb38b8 Time: 0.0318313\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe2866ff18c9049f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe2866ff18c9049f9 Time: 0.0298116\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xe67db95e0c20b618\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe67db95e0c20b618 Time: 0.016222\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xef1e5139c624a44f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xef1e5139c624a44f Time: 0.0330996\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_t1r1s1 Tactic: 0xf883bd61103a5c32\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xf883bd61103a5c32 Time: 0.0202002\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xfbff59172cce263c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbff59172cce263c Time: 0.022998\n",
            "TRT - VERBOSE\n",
            "sequential/dense_1/MatMul + sequential/dense_1/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xfcd06da0f3c31fd1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfcd06da0f3c31fd1 Time: 0.0237319\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x017a89ce2d82b850 Time: 0.0101754\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x017a89ce2d82b850\n",
            "TRT - VERBOSE\n",
            "=============== Computing costs for \n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(144,1,1,1) -> Float(63,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0303058\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0301796\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0766699\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.198299\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.0572658\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.0303341\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000039 Time: 0.0147117\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.076704\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 0.198064\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.0571431\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000039 Time: 0.0147117\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0274084\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0293413\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0274084\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x128_relu_interior_nn_v1 Tactic: 0x18597bd4a7d0164d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x18597bd4a7d0164d Time: 0.0717013\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x128_relu_medium_nn_v1 Tactic: 0x195431d38ba5af88\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x195431d38ba5af88 Time: 0.0726016\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x25eed4cfa195d49d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x25eed4cfa195d49d Time: 0.0491215\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x128_relu_small_nn_v1 Tactic: 0x365602d0613d4c36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x365602d0613d4c36 Time: 0.0719019\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x5193693bc0732c65\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5193693bc0732c65 Time: 0.0321978\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x64_relu_small_nn_v1 Tactic: 0x5e7d1125e7896624\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5e7d1125e7896624 Time: 0.0479284\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x64_relu_interior_nn_v1 Tactic: 0x7e29bdfccd92c42c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e29bdfccd92c42c Time: 0.0468787\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x64_relu_medium_nn_v1 Tactic: 0x90238daf8750ddb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x90238daf8750ddb0 Time: 0.0501882\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa0dcf7c2b333d150\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa0dcf7c2b333d150 Time: 0.0552899\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa3cd285aae791bdd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa3cd285aae791bdd Time: 0.0322783\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaa0953b1a73b0b9b Time: 0.0234809\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x32_relu_medium_nn_v1 Tactic: 0xc2a5fc6b5e7cef5e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc2a5fc6b5e7cef5e Time: 0.0375538\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_scudnn_128x32_relu_small_nn_v1 Tactic: 0xc939b7b0a4d5a05f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc939b7b0a4d5a05f Time: 0.0497676\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.0234809\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0x0000000000000039\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(144,1,144,144) -> Float(63,1,63,63) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x704db0897ce9340d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x704db0897ce9340d Time: 0.028632\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa79cf41de521f476\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa79cf41de521f476 Time: 0.048189\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xded29d328f8f7228\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xded29d328f8f7228 Time: 0.0277251\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage1_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xe957dcfcec24ec5d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe957dcfcec24ec5d Time: 0.0473307\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfbba95cf52891795\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbba95cf52891795 Time: 0.047388\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xded29d328f8f7228 Time: 0.0277251\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xded29d328f8f7228\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(144,1,1,1) -> Half(63,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0625493\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.134304\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.104133\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.194128\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.113792\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.0771712\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.10428\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 0.196475\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.102576\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0625493\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0269087\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0275635\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0270326\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000003 Time: 0.0271795\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.0377434\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.0353909\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000006 Time: 0.0324228\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000007 Time: 0.0319709\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0269087\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(72,1:2,1,1) -> Half(63,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9306c3a1111e5472 Time: 0.00785588\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x9306c3a1111e5472 Time: 0.00785588\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(72,1:2,1,1) -> Half(32,1:2,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x16eafdbc5869b184\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x16eafdbc5869b184 Time: 0.0300587\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x21904dd9d0cd407e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21904dd9d0cd407e Time: 0.0299218\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x3bee4a098b4f8914\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3bee4a098b4f8914 Time: 0.0290071\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x446c8c788145836a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x446c8c788145836a Time: 0.0301707\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x73163c1d09e17290\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x73163c1d09e17290 Time: 0.030264\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x7498280d2c59e4aa\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7498280d2c59e4aa Time: 0.0286178\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0x87e5c2a636a0d1f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x87e5c2a636a0d1f8 Time: 0.0409339\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0x97afba3735828021\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x97afba3735828021 Time: 0.0279227\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0x9ce6ebc390e62b01\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9ce6ebc390e62b01 Time: 0.028264\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xacaaec9cc8134f6f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xacaaec9cc8134f6f Time: 0.0294329\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0xb09f72c3be042002\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb09f72c3be042002 Time: 0.0407941\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0xc72182f0fce13bb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc72182f0fce13bb0 Time: 0.0278907\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0xcc68d30459859090\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xcc68d30459859090 Time: 0.0279404\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xccca8c966967f8f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xccca8c966967f8f8 Time: 0.0409683\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdb5acaea7b0746d5\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdb5acaea7b0746d5 Time: 0.0405179\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdcd3fec139dd130a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdcd3fec139dd130a Time: 0.0404184\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xe3dc8e986f0522d1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe3dc8e986f0522d1 Time: 0.0282756\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xe4aed86f94a0620c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe4aed86f94a0620c Time: 0.041005\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xc72182f0fce13bb0 Time: 0.0278907\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc72182f0fce13bb0\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(18,1:8,18,18) -> Float(63,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(18,1:8,18,18) -> Half(8,1:8,8,8) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_2/MatMul + sequential/dense_2/Relu.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_2/MatMul + sequential/dense_2/Relu (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x0129597ad9bbff14\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0129597ad9bbff14 Time: 0.0125333\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x017a89ce2d82b850\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x017a89ce2d82b850 Time: 0.010998\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x105f56cf03ee5549\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x105f56cf03ee5549 Time: 0.0303387\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x1d38ef2fc1ec5804\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1d38ef2fc1ec5804 Time: 0.0344917\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x1dcf9babce3d9b3b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1dcf9babce3d9b3b Time: 0.0219433\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x21739cdb4c6113ed\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21739cdb4c6113ed Time: 0.0335712\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r1s1 Tactic: 0x22dbd03ae6f5a915\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x22dbd03ae6f5a915 Time: 0.0233031\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x249110624ee04937\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x249110624ee04937 Time: 0.0158235\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x255200b1b31c45cd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x255200b1b31c45cd Time: 0.046216\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x26d4c2773a9a6efc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x26d4c2773a9a6efc Time: 0.0302338\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x2a3615ad33745f0b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2a3615ad33745f0b Time: 0.0223652\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x2ae5fedb80fbd388\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2ae5fedb80fbd388 Time: 0.0297849\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x2c6739dc8daca583\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2c6739dc8daca583 Time: 0.0231687\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x34192289eb1f5427\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x34192289eb1f5427 Time: 0.028168\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x3693535b668f43cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3693535b668f43cb Time: 0.0227179\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x399448b5af8ca81a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x399448b5af8ca81a Time: 0.0154705\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x3f3840edab5c9d44\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3f3840edab5c9d44 Time: 0.0217807\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x41e8a431d0137286\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x41e8a431d0137286 Time: 0.0181474\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x4c17dc9d992e6a1d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4c17dc9d992e6a1d Time: 0.018957\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x4ea23ec81add686f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4ea23ec81add686f Time: 0.0282516\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x51e3312bfd062f36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x51e3312bfd062f36 Time: 0.0198205\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x523aca1fca7ef548\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x523aca1fca7ef548 Time: 0.0432973\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x53422c5d4478d3d7\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x53422c5d4478d3d7 Time: 0.0185973\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x5cb7625ea24db701\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5cb7625ea24db701 Time: 0.0332373\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x62a22cfa1199e58e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x62a22cfa1199e58e Time: 0.0124796\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x63566dea68ccc247\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x63566dea68ccc247 Time: 0.0282542\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x6d1428d5257a3dc9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x6d1428d5257a3dc9 Time: 0.0327118\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x72f623a1c870d417\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x72f623a1c870d417 Time: 0.028008\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7585679fc3cc2536\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7585679fc3cc2536 Time: 0.032257\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x77a26840a2ace0b3\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77a26840a2ace0b3 Time: 0.0323656\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x77ef8bb029e1d4e0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77ef8bb029e1d4e0 Time: 0.0338005\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7ca057c91d677737\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7ca057c91d677737 Time: 0.0174763\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x7e665af4f37d210b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e665af4f37d210b Time: 0.0185896\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x81a7be09ad63581a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x81a7be09ad63581a Time: 0.0225237\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x833510adbbf772c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x833510adbbf772c4 Time: 0.0232647\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x83b35618df65874c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83b35618df65874c Time: 0.0204022\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x83c3f470a0ec89f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83c3f470a0ec89f9 Time: 0.0315782\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8480e919254b99f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8480e919254b99f8 Time: 0.0352256\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_t1r1s1 Tactic: 0x8639a0d23c8a1708\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8639a0d23c8a1708 Time: 0.0314269\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x86937c170a111d1f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x86937c170a111d1f Time: 0.0325547\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x89c2d153627e52ba\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x89c2d153627e52ba Time: 0.0180194\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8a37d1d6d41033e6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8a37d1d6d41033e6 Time: 0.046436\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x8b8a7a5cef8d932b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8b8a7a5cef8d932b Time: 0.0429747\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x911cdd8d308bed5c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x911cdd8d308bed5c Time: 0.0171237\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x93125939e1fba374\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x93125939e1fba374 Time: 0.0466587\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x9774d044044b6a7d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9774d044044b6a7d Time: 0.0164018\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xa8f10051cbdaaa96\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa8f10051cbdaaa96 Time: 0.0260119\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xaf407014f2c7f1cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaf407014f2c7f1cb Time: 0.0243825\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb26ad7a19a3195cc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb26ad7a19a3195cc Time: 0.018653\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb3989f8802666c8a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb3989f8802666c8a Time: 0.0257157\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb5342eac22cbe342\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5342eac22cbe342 Time: 0.0461107\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb5fdd9dd73a52c67\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5fdd9dd73a52c67 Time: 0.0159492\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xb8eb6a106c53cff6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb8eb6a106c53cff6 Time: 0.0233877\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xba86f9c788dfb2dc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xba86f9c788dfb2dc Time: 0.0246415\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xc110e19c9f5aa36e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc110e19c9f5aa36e Time: 0.0430627\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc399fdbffdc34032\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc399fdbffdc34032 Time: 0.0269998\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc6f99965cbd03fdf\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc6f99965cbd03fdf Time: 0.0323365\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd313af1c92b241c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd313af1c92b241c4 Time: 0.0279556\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd47a5fce3824e4a4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd47a5fce3824e4a4 Time: 0.022806\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r1s1 Tactic: 0xd8c128ae16cb4132\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd8c128ae16cb4132 Time: 0.0198776\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0xdadc728a0ae041d9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdadc728a0ae041d9 Time: 0.015649\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xdbe57b4edf7481d8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdbe57b4edf7481d8 Time: 0.0232711\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xdc1c841ef1cd3e8e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc1c841ef1cd3e8e Time: 0.0340789\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xdc559b3944b0cdf8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc559b3944b0cdf8 Time: 0.0176196\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xde62c240f3a7d930\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xde62c240f3a7d930 Time: 0.0324674\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe281d0b88acb38b8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe281d0b88acb38b8 Time: 0.0312902\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe2866ff18c9049f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe2866ff18c9049f9 Time: 0.0299458\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xe67db95e0c20b618\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe67db95e0c20b618 Time: 0.0261177\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xef1e5139c624a44f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xef1e5139c624a44f Time: 0.0329202\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_t1r1s1 Tactic: 0xf883bd61103a5c32\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xf883bd61103a5c32 Time: 0.0238705\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xfbff59172cce263c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbff59172cce263c Time: 0.0228103\n",
            "TRT - VERBOSE\n",
            "sequential/dense_2/MatMul + sequential/dense_2/Relu Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xfcd06da0f3c31fd1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfcd06da0f3c31fd1 Time: 0.0247787\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x017a89ce2d82b850 Time: 0.010998\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x017a89ce2d82b850\n",
            "TRT - VERBOSE\n",
            "=============== Computing costs for \n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(63,1,1,1) -> Float(10,1,1,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0177039\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0176898\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0399028\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.045468\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.0412326\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.0176662\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000039 Time: 0.0103693\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.0398779\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 0.044908\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.0410074\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000039 Time: 0.0103693\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.028072\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0335253\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.028072\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x128_relu_interior_nn_v1 Tactic: 0x18597bd4a7d0164d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x18597bd4a7d0164d Time: 0.041712\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x128_relu_medium_nn_v1 Tactic: 0x195431d38ba5af88\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x195431d38ba5af88 Time: 0.0422307\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x25eed4cfa195d49d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x25eed4cfa195d49d Time: 0.0306987\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x128_relu_small_nn_v1 Tactic: 0x365602d0613d4c36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x365602d0613d4c36 Time: 0.0418307\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x5193693bc0732c65\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5193693bc0732c65 Time: 0.0207423\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x64_relu_small_nn_v1 Tactic: 0x5e7d1125e7896624\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5e7d1125e7896624 Time: 0.0304165\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x64_relu_interior_nn_v1 Tactic: 0x7e29bdfccd92c42c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e29bdfccd92c42c Time: 0.0299413\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x64_relu_medium_nn_v1 Tactic: 0x90238daf8750ddb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x90238daf8750ddb0 Time: 0.0314114\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa0dcf7c2b333d150\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa0dcf7c2b333d150 Time: 0.037171\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa3cd285aae791bdd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa3cd285aae791bdd Time: 0.0218113\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaa0953b1a73b0b9b Time: 0.0225842\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x32_relu_medium_nn_v1 Tactic: 0xc2a5fc6b5e7cef5e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc2a5fc6b5e7cef5e Time: 0.0255246\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_scudnn_128x32_relu_small_nn_v1 Tactic: 0xc939b7b0a4d5a05f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc939b7b0a4d5a05f Time: 0.0310749\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x5193693bc0732c65 Time: 0.0207423\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0x0000000000000039\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(63,1,63,63) -> Float(10,1,10,10) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x704db0897ce9340d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x704db0897ce9340d Time: 0.0197773\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xa79cf41de521f476\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa79cf41de521f476 Time: 0.0330095\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xded29d328f8f7228\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xded29d328f8f7228 Time: 0.0185517\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage1_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xe957dcfcec24ec5d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe957dcfcec24ec5d Time: 0.0314114\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage1_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfbba95cf52891795\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbba95cf52891795 Time: 0.0349643\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0xded29d328f8f7228 Time: 0.0185517\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xded29d328f8f7228\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(63,1,1,1) -> Half(10,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CudnnConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0875627\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0675776\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0687893\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.094616\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.0955893\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000038 Time: 0.0535101\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003a Time: 0.0681088\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003c Time: 0.0939253\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x000000000000003d Time: 0.097248\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000038 Time: 0.0535101\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0284569\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0282471\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000002 Time: 0.0273428\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000003 Time: 0.0272697\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000004 Time: 0.034448\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000005 Time: 0.0334368\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000006 Time: 0.0287911\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000007 Time: 0.0285751\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000003 Time: 0.0272697\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0x0000000000000003\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(32,1:2,1,1) -> Half(10,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_conv1x1_f16f16_f16_f16_nchw_vect_c_2kcrs_vect_c_2_nchw_simt_small_batch_bias_relu Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9306c3a1111e5472 Time: 0.0231388\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x9306c3a1111e5472 Time: 0.0231388\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9306c3a1111e5472\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(32,1:2,1,1) -> Half(5,1:2,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (FusedConvActConvolution)\n",
            "TRT - VERBOSE\n",
            "FusedConvActConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x16eafdbc5869b184\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x16eafdbc5869b184 Time: 0.0234617\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 0x21904dd9d0cd407e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21904dd9d0cd407e Time: 0.0233543\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x3bee4a098b4f8914\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3bee4a098b4f8914 Time: 0.0227797\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x446c8c788145836a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x446c8c788145836a Time: 0.0245379\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 0x73163c1d09e17290\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x73163c1d09e17290 Time: 0.0236295\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 0x7498280d2c59e4aa\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7498280d2c59e4aa Time: 0.0226859\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0x87e5c2a636a0d1f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x87e5c2a636a0d1f8 Time: 0.0295404\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0x97afba3735828021\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x97afba3735828021 Time: 0.0221833\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0x9ce6ebc390e62b01\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9ce6ebc390e62b01 Time: 0.0223851\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xacaaec9cc8134f6f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xacaaec9cc8134f6f Time: 0.0227975\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: 0xb09f72c3be042002\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb09f72c3be042002 Time: 0.0296036\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 0xc72182f0fce13bb0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc72182f0fce13bb0 Time: 0.0223253\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 0xcc68d30459859090\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xcc68d30459859090 Time: 0.0223054\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xccca8c966967f8f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xccca8c966967f8f8 Time: 0.0297369\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdb5acaea7b0746d5\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdb5acaea7b0746d5 Time: 0.0293431\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: 0xdcd3fec139dd130a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdcd3fec139dd130a Time: 0.0291822\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 0xe3dc8e986f0522d1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe3dc8e986f0522d1 Time: 0.0224932\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 0xe4aed86f94a0620c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe4aed86f94a0620c Time: 0.029896\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x97afba3735828021 Time: 0.0221833\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x97afba3735828021\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(8,1:8,8,8) -> Float(10,1,1,1) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "CaskConvolution has no valid tactics for this config, skipping\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(8,1:8,8,8) -> Half(2,1:8,2,2) ***************\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CudaDepthwiseConvolution)\n",
            "TRT - VERBOSE\n",
            "CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CublasConvolution)\n",
            "TRT - VERBOSE\n",
            "CublasConvolution has no valid tactics for this config, skipping\n",
            "TRT - WARNING\n",
            "Weights [name=sequential/dense_3/MatMul.weight] had the following issues when converted to FP16:\n",
            "TRT - WARNING\n",
            " - Subnormal FP16 values detected. \n",
            "TRT - WARNING\n",
            "If this is not the desired behavior, please modify the weights or retrain with regularization to reduce the magnitude of the weights.\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/MatMul (CaskConvolution)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x0129597ad9bbff14\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0129597ad9bbff14 Time: 0.023301\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x017a89ce2d82b850\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x017a89ce2d82b850 Time: 0.0269276\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x105f56cf03ee5549\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x105f56cf03ee5549 Time: 0.0203464\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x1d38ef2fc1ec5804\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1d38ef2fc1ec5804 Time: 0.0212667\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x1dcf9babce3d9b3b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x1dcf9babce3d9b3b Time: 0.0186536\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x21739cdb4c6113ed\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x21739cdb4c6113ed Time: 0.0246347\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r1s1 Tactic: 0x22dbd03ae6f5a915\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x22dbd03ae6f5a915 Time: 0.0202102\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x249110624ee04937\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x249110624ee04937 Time: 0.0170432\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x255200b1b31c45cd\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x255200b1b31c45cd Time: 0.0324228\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x26d4c2773a9a6efc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x26d4c2773a9a6efc Time: 0.0258855\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x2a3615ad33745f0b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2a3615ad33745f0b Time: 0.0214527\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x2ae5fedb80fbd388\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2ae5fedb80fbd388 Time: 0.0244884\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x2c6739dc8daca583\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x2c6739dc8daca583 Time: 0.0199887\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x34192289eb1f5427\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x34192289eb1f5427 Time: 0.0206532\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x3693535b668f43cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3693535b668f43cb Time: 0.0200176\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x399448b5af8ca81a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x399448b5af8ca81a Time: 0.0171376\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x3f3840edab5c9d44\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x3f3840edab5c9d44 Time: 0.01872\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x41e8a431d0137286\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x41e8a431d0137286 Time: 0.01192\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x4c17dc9d992e6a1d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4c17dc9d992e6a1d Time: 0.0162194\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x4ea23ec81add686f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x4ea23ec81add686f Time: 0.0205038\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x51e3312bfd062f36\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x51e3312bfd062f36 Time: 0.0176303\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x523aca1fca7ef548\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x523aca1fca7ef548 Time: 0.0291804\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x53422c5d4478d3d7\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x53422c5d4478d3d7 Time: 0.0154996\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x5cb7625ea24db701\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x5cb7625ea24db701 Time: 0.0235371\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x62a22cfa1199e58e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x62a22cfa1199e58e Time: 0.0190193\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x63566dea68ccc247\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x63566dea68ccc247 Time: 0.0221047\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0x6d1428d5257a3dc9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x6d1428d5257a3dc9 Time: 0.0233195\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x72f623a1c870d417\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x72f623a1c870d417 Time: 0.0207373\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7585679fc3cc2536\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7585679fc3cc2536 Time: 0.0262835\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x77a26840a2ace0b3\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77a26840a2ace0b3 Time: 0.0263787\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x77ef8bb029e1d4e0\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x77ef8bb029e1d4e0 Time: 0.0246248\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x7ca057c91d677737\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7ca057c91d677737 Time: 0.0158061\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x7e665af4f37d210b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x7e665af4f37d210b Time: 0.0158337\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x81a7be09ad63581a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x81a7be09ad63581a Time: 0.0214993\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0x833510adbbf772c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x833510adbbf772c4 Time: 0.0191544\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x83b35618df65874c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83b35618df65874c Time: 0.0168107\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x83c3f470a0ec89f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x83c3f470a0ec89f9 Time: 0.0255771\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8480e919254b99f8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8480e919254b99f8 Time: 0.0262096\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_t1r1s1 Tactic: 0x8639a0d23c8a1708\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8639a0d23c8a1708 Time: 0.0221973\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x86937c170a111d1f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x86937c170a111d1f Time: 0.0268291\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x89c2d153627e52ba\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x89c2d153627e52ba Time: 0.0186619\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x8a37d1d6d41033e6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8a37d1d6d41033e6 Time: 0.0329396\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0x8b8a7a5cef8d932b\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x8b8a7a5cef8d932b Time: 0.0287129\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0x911cdd8d308bed5c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x911cdd8d308bed5c Time: 0.0119055\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_t1r1s1 Tactic: 0x93125939e1fba374\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x93125939e1fba374 Time: 0.0330366\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x9774d044044b6a7d\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x9774d044044b6a7d Time: 0.0154885\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xa8f10051cbdaaa96\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xa8f10051cbdaaa96 Time: 0.0209813\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xaf407014f2c7f1cb\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xaf407014f2c7f1cb Time: 0.021402\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb26ad7a19a3195cc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb26ad7a19a3195cc Time: 0.0171589\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb3989f8802666c8a\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb3989f8802666c8a Time: 0.021676\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xb5342eac22cbe342\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5342eac22cbe342 Time: 0.032096\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xb5fdd9dd73a52c67\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb5fdd9dd73a52c67 Time: 0.0152141\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xb8eb6a106c53cff6\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xb8eb6a106c53cff6 Time: 0.021036\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xba86f9c788dfb2dc\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xba86f9c788dfb2dc Time: 0.0229668\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xc110e19c9f5aa36e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc110e19c9f5aa36e Time: 0.0288844\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc399fdbffdc34032\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc399fdbffdc34032 Time: 0.0229298\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xc6f99965cbd03fdf\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xc6f99965cbd03fdf Time: 0.0263385\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd313af1c92b241c4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd313af1c92b241c4 Time: 0.0212607\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 0xd47a5fce3824e4a4\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd47a5fce3824e4a4 Time: 0.0203351\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r1s1 Tactic: 0xd8c128ae16cb4132\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xd8c128ae16cb4132 Time: 0.0567876\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor8x8x4_t1r1s1 Tactic: 0xdadc728a0ae041d9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdadc728a0ae041d9 Time: 0.0255665\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xdbe57b4edf7481d8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdbe57b4edf7481d8 Time: 0.0197961\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xdc1c841ef1cd3e8e\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc1c841ef1cd3e8e Time: 0.0247109\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xdc559b3944b0cdf8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xdc559b3944b0cdf8 Time: 0.0170827\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: volta_h884cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xde62c240f3a7d930\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xde62c240f3a7d930 Time: 0.0228139\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe281d0b88acb38b8\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe281d0b88acb38b8 Time: 0.0219253\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor8x8x4_simple_t1r1s1 Tactic: 0xe2866ff18c9049f9\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe2866ff18c9049f9 Time: 0.0234496\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0xe67db95e0c20b618\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xe67db95e0c20b618 Time: 0.0224548\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 0xef1e5139c624a44f\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xef1e5139c624a44f Time: 0.0236572\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm70_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_t1r1s1 Tactic: 0xf883bd61103a5c32\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xf883bd61103a5c32 Time: 0.0242248\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0xfbff59172cce263c\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfbff59172cce263c Time: 0.0222222\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/MatMul Set Tactic Name: turing_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 0xfcd06da0f3c31fd1\n",
            "TRT - VERBOSE\n",
            "Tactic: 0xfcd06da0f3c31fd1 Time: 0.0185748\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x911cdd8d308bed5c Time: 0.0119055\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x911cdd8d308bed5c\n",
            "TRT - VERBOSE\n",
            "=============== Computing costs for \n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(10,1,1,1) -> Float(10,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: reshape_after_sequential/dense_3/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0264985\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.04616\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0264985\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(10,1,1,1) -> Half(10,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: reshape_after_sequential/dense_3/MatMul (Shuffle)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000000 Time: 0.0276521\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0000000000000001 Time: 0.0434987\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0000000000000000 Time: 0.0276521\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
            "TRT - VERBOSE\n",
            "=============== Computing costs for \n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Float(10,1) -> Float(10,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/Softmax (CudaSoftMax)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0251459\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e9 Time: 0.0243055\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e9 Time: 0.0243055\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 0x00000000000003e9\n",
            "TRT - VERBOSE\n",
            "*************** Autotuning format combination: Half(10,1) -> Half(10,1) ***************\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/Softmax (CudaSoftMax)\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003ea Time: 0.0084\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x00000000000003e9 Time: 0.00586386\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x00000000000003e9 Time: 0.00586386\n",
            "TRT - VERBOSE\n",
            "--------------- Timing Runner: sequential/dense_3/Softmax (CaskSoftMax)\n",
            "TRT - VERBOSE\n",
            "sequential/dense_3/Softmax Set Tactic Name: cutlass_softmax_fwd_scalar_fp16_accurate_channel Tactic: 0x0cf7b28fb5e72618\n",
            "TRT - VERBOSE\n",
            "Tactic: 0x0cf7b28fb5e72618 Time: 0.00973166\n",
            "TRT - VERBOSE\n",
            "Fastest Tactic: 0x0cf7b28fb5e72618 Time: 0.00973166\n",
            "TRT - VERBOSE\n",
            ">>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 0x00000000000003e9\n",
            "TRT - VERBOSE\n",
            "Adding reformat layer: Reformatted Input Tensor 0 to sequential/dense_3/Softmax (sequential/dense_3/BiasAdd:0) from Float(10,1) to Half(10,1)\n",
            "TRT - VERBOSE\n",
            "Adding reformat layer: Reformatted Output Tensor 0 to sequential/dense_3/Softmax (dense_3) from Half(10,1) to Float(10,1)\n",
            "TRT - VERBOSE\n",
            "For layer sequential/dense/MatMul + sequential/dense/Relu a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Set BuilderFlag::kPREFER_PRECISION_CONSTRAINTS to encourage choosing a conforming implementation, or set BuilderFlag::kOBEY_PRECISION_CONSTRAINTS to require choosing a conforming implementation.\n",
            "TRT - VERBOSE\n",
            "For layer sequential/dense_1/MatMul + sequential/dense_1/Relu a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Set BuilderFlag::kPREFER_PRECISION_CONSTRAINTS to encourage choosing a conforming implementation, or set BuilderFlag::kOBEY_PRECISION_CONSTRAINTS to require choosing a conforming implementation.\n",
            "TRT - VERBOSE\n",
            "For layer sequential/dense_2/MatMul + sequential/dense_2/Relu a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Set BuilderFlag::kPREFER_PRECISION_CONSTRAINTS to encourage choosing a conforming implementation, or set BuilderFlag::kOBEY_PRECISION_CONSTRAINTS to require choosing a conforming implementation.\n",
            "TRT - VERBOSE\n",
            "Formats and tactics selection completed in 4.99166 seconds.\n",
            "TRT - VERBOSE\n",
            "After reformat layers: 9 layers\n",
            "TRT - VERBOSE\n",
            "Pre-optimized block assignment.\n",
            "TRT - VERBOSE\n",
            "Block size 4\n",
            "TRT - VERBOSE\n",
            "Block size 4\n",
            "TRT - VERBOSE\n",
            "Block size 512\n",
            "TRT - VERBOSE\n",
            "Block size 1024\n",
            "TRT - VERBOSE\n",
            "Block size 1024\n",
            "TRT - VERBOSE\n",
            "Block size 512\n",
            "TRT - VERBOSE\n",
            "Block size 512\n",
            "TRT - VERBOSE\n",
            "Block size 512\n",
            "TRT - VERBOSE\n",
            "Block size 1073741824\n",
            "TRT - VERBOSE\n",
            "Total Activation Memory: 1073745928\n",
            "TRT - INFO\n",
            "Detected 1 inputs and 1 output network tensors.\n",
            "TRT - VERBOSE\n",
            "Layer: sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
            "TRT - VERBOSE\n",
            "Layer: sequential/dense/MatMul + sequential/dense/Relu Host Persistent: 32 Device Persistent: 0 Scratch Memory: 1024\n",
            "TRT - VERBOSE\n",
            "Layer: sequential/dense_1/MatMul + sequential/dense_1/Relu Host Persistent: 32 Device Persistent: 0 Scratch Memory: 0\n",
            "TRT - VERBOSE\n",
            "Layer: sequential/dense_2/MatMul + sequential/dense_2/Relu Host Persistent: 32 Device Persistent: 0 Scratch Memory: 512\n",
            "TRT - VERBOSE\n",
            "Layer: sequential/dense_3/MatMul Host Persistent: 32 Device Persistent: 0 Scratch Memory: 512\n",
            "TRT - VERBOSE\n",
            "Layer: reshape_after_sequential/dense_3/MatMul Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
            "TRT - VERBOSE\n",
            "Layer: Reformatting CopyNode for Input Tensor 0 to sequential/dense_3/Softmax Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
            "TRT - VERBOSE\n",
            "Layer: sequential/dense_3/Softmax Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
            "TRT - VERBOSE\n",
            "Layer: Reformatting CopyNode for Output Tensor 0 to sequential/dense_3/Softmax Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0\n",
            "TRT - INFO\n",
            "Total Host Persistent Memory: 128\n",
            "TRT - INFO\n",
            "Total Device Persistent Memory: 0\n",
            "TRT - INFO\n",
            "Total Scratch Memory: 1024\n",
            "TRT - INFO\n",
            "[MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 270 MiB\n",
            "TRT - INFO\n",
            "[BlockAssignment] Algorithm ShiftNTopDown took 0.053304ms to assign 3 blocks to 11 nodes requiring 2560 bytes.\n",
            "TRT - VERBOSE\n",
            "Optimized block assignment.\n",
            "TRT - VERBOSE\n",
            "Block size 1024\n",
            "TRT - VERBOSE\n",
            "Block size 1024\n",
            "TRT - VERBOSE\n",
            "Block size 512\n",
            "TRT - INFO\n",
            "Total Activation Memory: 2560\n",
            "TRT - VERBOSE\n",
            "Disabling unused tactic source: CUBLAS, CUBLAS_LT\n",
            "TRT - VERBOSE\n",
            "Disabling unused tactic source: EDGE_MASK_CONVOLUTIONS\n",
            "TRT - VERBOSE\n",
            "Using cuDNN as a tactic source\n",
            "TRT - INFO\n",
            "[MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 0, GPU 1311 (MiB)\n",
            "TRT - WARNING\n",
            "TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n",
            "TRT - VERBOSE\n",
            "Engine generation completed in 5.04785 seconds.\n",
            "TRT - VERBOSE\n",
            "Deleting timing cache: 135 entries, served 0 hits since creation.\n",
            "TRT - VERBOSE\n",
            "Engine Layer Information:\n",
            "Layer(NoOp): sequential/flatten/Reshape + reshape_before_sequential/dense/MatMul, Tactic: 0x0000000000000000, input_1[Float(1,28,28,1)] -> reshape_before_sequential/dense/MatMul_out_region[Float(1,784,1,1)]\n",
            "Layer(CudnnConvolution): sequential/dense/MatMul + sequential/dense/Relu, Tactic: 0x0000000000000039, reshape_before_sequential/dense/MatMul_out_region[Float(1,784,1,1)] -> sequential/dense/Relu_out_tensor[Float(1,155,1,1)]\n",
            "Layer(CudnnConvolution): sequential/dense_1/MatMul + sequential/dense_1/Relu, Tactic: 0x0000000000000039, sequential/dense/Relu_out_tensor[Float(1,155,1,1)] -> sequential/dense_1/Relu_out_tensor[Float(1,144,1,1)]\n",
            "Layer(CudnnConvolution): sequential/dense_2/MatMul + sequential/dense_2/Relu, Tactic: 0x0000000000000039, sequential/dense_1/Relu_out_tensor[Float(1,144,1,1)] -> sequential/dense_2/Relu_out_tensor[Float(1,63,1,1)]\n",
            "Layer(CudnnConvolution): sequential/dense_3/MatMul, Tactic: 0x0000000000000039, sequential/dense_2/Relu_out_tensor[Float(1,63,1,1)] -> sequential/dense_3/MatMul_out_region[Float(1,10,1,1)]\n",
            "Layer(NoOp): reshape_after_sequential/dense_3/MatMul, Tactic: 0x0000000000000000, sequential/dense_3/MatMul_out_region[Float(1,10,1,1)] -> sequential/dense_3/BiasAdd:0[Float(1,10)]\n",
            "Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to sequential/dense_3/Softmax, Tactic: 0x0000000000000000, sequential/dense_3/BiasAdd:0[Float(1,10)] -> Reformatted Input Tensor 0 to sequential/dense_3/Softmax[Half(1,10)]\n",
            "Layer(CudaSoftMax): sequential/dense_3/Softmax, Tactic: 0x00000000000003e9, Reformatted Input Tensor 0 to sequential/dense_3/Softmax[Half(1,10)] -> Reformatted Output Tensor 0 to sequential/dense_3/Softmax[Half(1,10)]\n",
            "Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to sequential/dense_3/Softmax, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to sequential/dense_3/Softmax[Half(1,10)] -> dense_3[Float(1,10)]\n",
            "TRT - INFO\n",
            "[MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)\n",
            "TRT - WARNING\n",
            "The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
            "TRT - WARNING\n",
            "The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
            "TRT engine -  2560  Bytes\n",
            "TRT engine number of layers -  9\n",
            "TRT engine number of bindings -  2\n",
            "TRT engine number of profils -  1\n",
            "Completion optimized model\n",
            "TRT - VERBOSE\n",
            "Using cuDNN as a tactic source\n",
            "TRT - INFO\n",
            "[MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 0, GPU 1295 (MiB)\n",
            "TRT - WARNING\n",
            "TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n",
            "TRT - VERBOSE\n",
            "Total per-runner device persistent memory is 0\n",
            "TRT - VERBOSE\n",
            "Total per-runner host persistent memory is 128\n",
            "TRT - VERBOSE\n",
            "Allocated activation device memory of size 2560\n",
            "TRT - INFO\n",
            "[MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 4 (MiB)\n",
            "TRT inference exception ERROR -  'numpy.ndarray' object has no attribute 'host'\n",
            "TRT inference exception ERROR -  'numpy.ndarray' object has no attribute 'host'\n",
            "TRT Keras inference average time is: 0.141143798828125 milliseconds\n",
            "TRT Keras inference average FPS is: 7084.972972972973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  del(parser)\n",
        "  del(modelName)\n",
        "  del(builder)\n",
        "  del(optimizationProfiler)\n",
        "  del(calib)\n",
        "  del(config)\n",
        "  del(network)\n",
        "  del(engine)\n",
        "  del(runtime)\n",
        "  del(context)\n",
        "  del(inputs)\n",
        "  del(outputs)\n",
        "  del(bindings)\n",
        "  del(stream)"
      ],
      "metadata": {
        "id": "0kkriKbKrsot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}